[
  {
    "layer": 0,
    "samples": [
      {
        "sample_idx": 0,
        "original": "The history of Nero's reign is problematic in that no historical sources survived that were contemporary with Nero. These first histories at one time did exist and were described as biased and fantastical, either overly critical or praising of Nero. The original sources were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 1.10 GiB. GPU 0 has a total capacity of 79.44 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 47.37 GiB memory in use. Process 121765 has 15.52 GiB memory in use. Process 121890 has 15.52 GiB memory in use. Of the allocated memory 46.49 GiB is allocated by PyTorch, and 284.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 1,
        "original": "Ironclads were designed for several roles, including as high seas battleships, coastal defense ships, and long @-@ range cruisers. The rapid evolution of warship design in the late 19th century transformed the ironclad from a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.56 MiB is free. Including non-PyTorch memory, this process has 15.81 GiB memory in use. Process 121765 has 22.25 GiB memory in use. Process 121890 has 25.82 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 3.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 2,
        "original": "The track became the group's sixth top @-@ ten hit in Ireland and the United Kingdom, while attaining top @-@ forty positions in both Belgian territories ( Flanders and Wallonia ), as well as in Australia, Canada,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.56 MiB is free. Including non-PyTorch memory, this process has 15.82 GiB memory in use. Process 121765 has 22.25 GiB memory in use. Process 121890 has 25.82 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Of the allocated memory 15.18 GiB is allocated by PyTorch, and 39.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 3,
        "original": "The band began touring in support of the album prior to its release, initiating touring with several free shows in the US. Followed by multiple appearances at festivals in Europe. They then joined Korn for their 2006 edition of Family Values Tour across",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.56 MiB is free. Including non-PyTorch memory, this process has 15.81 GiB memory in use. Process 121765 has 22.25 GiB memory in use. Process 121890 has 25.82 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 45.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 4,
        "original": "Imagism was a movement in early 20th @-@ century Anglo @-@ American poetry that favored precision of imagery and clear, sharp language.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.56 MiB is free. Including non-PyTorch memory, this process has 15.84 GiB memory in use. Process 121765 has 22.04 GiB memory in use. Process 121890 has 26.01 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 775.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 5,
        "original": "Kershaw finished 2012 with a 14 \u2013 9 record, a 2 @.@ 53 ERA ( leading the league ), 229 strikeouts, and 2272 \u2044 3 innings pitched, coming second in both categories",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.56 MiB is free. Including non-PyTorch memory, this process has 15.84 GiB memory in use. Process 121765 has 22.04 GiB memory in use. Process 121890 has 26.01 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Of the allocated memory 15.18 GiB is allocated by PyTorch, and 56.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 6,
        "original": "NY 31B began at an intersection with its parent route, NY 31, in the Cayuga County village of Weedsport. The highway went eastward, intersecting with NY 34 less than 0 @.@ 1 miles (",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.56 MiB is free. Including non-PyTorch memory, this process has 15.84 GiB memory in use. Process 121765 has 22.04 GiB memory in use. Process 121890 has 26.01 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Of the allocated memory 15.18 GiB is allocated by PyTorch, and 61.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 7,
        "original": "The unsuitability of unarmored iron for warship hulls meant that iron was only adopted as a building material for battleships when protected by armor. However, iron gave the naval architect many advantages. Iron allowed larger ships and more flexible design",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.56 MiB is free. Including non-PyTorch memory, this process has 15.85 GiB memory in use. Process 121765 has 22.03 GiB memory in use. Process 121890 has 26.01 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Of the allocated memory 15.20 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 8,
        "original": "Both the Provisional and Official IRA stepped up attacks after Bloody Sunday, with the tacit support of the residents. Local feelings changed, however, with the killing of Ranger William Best by the Official IRA. Best was a 19 @-@ year",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.28 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 1.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 9,
        "original": "On October 27, 2000, Gomes was arrested for possession of marijuana while the band was performing in Waterbury, Connecticut. He was released on a US $ 1 @,@ 500 bond. In 2001, Hed PE",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.03 GiB memory in use. Process 121765 has 16.08 GiB memory in use. Process 121890 has 16.26 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.41 GiB is allocated by PyTorch, and 16.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 10,
        "original": "The headquarters of the Philippine Coast Guard is located at the South Harbor in Port Area near Intramuros and Ermita. The Philippine Navy on the other hand has its headquarters in Naval Station Jose Andrada located along Roxas Boulevard in Malate.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.08 GiB memory in use. Process 121765 has 16.04 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 15.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 11,
        "original": "It was announced in March 2006 that Stone Sour's second album, which was tentatively titled \" Come What May, \" would be released on July 18, 2006. However, the release date for the album was pushed back",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.05 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.45 GiB is allocated by PyTorch, and 4.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 12,
        "original": "The Mediterranean U @-@ boat Campaign lasted approximately from 21 September 1941 to May 1944. The Kriegsmarine tried to isolate Gibraltar, Malta, and Suez and disrupt Britain's trade routes. More than sixty U",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.02 GiB memory in use. Process 121765 has 16.09 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.41 GiB is allocated by PyTorch, and 10.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 13,
        "original": "A neutron spectrometer on board the Lunar Prospector spacecraft detected enhanced concentrations of hydrogen close to the northern and southern lunar poles, including the crater Shackleton. At the end of this mission in July 1999, the spacecraft was crashed into the nearby",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 6.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 14,
        "original": "That same afternoon, the North Koreans sent an American prisoner up the hill to Schmitt with the message, \" You have one hour to surrender or be blown to pieces. \" Failing in frontal infantry attack to reduce the little defending force, the North",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 6.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 15,
        "original": "Although Gore was well received by the British establishment, the work suffered from what Gore called a \" tediousness of process \", and he considered requesting a transfer in 1798. In 1800 it ground to a halt because another board established by",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 6.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 16,
        "original": "On December 15, 2011, Lesnar was charged with hunting infractions on a trip to Alberta on November 19, 2010. Two charges were dropped, but Lesnar pleaded guilty to the charge of improper tagging of an animal",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 6.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 17,
        "original": "Carl Falk \u2014 writing, production, programming, instruments, guitar, background vocals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 6.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 18,
        "original": "Shot by November 2012, the music video was characterised, in several MTV News interviews, as \" bigger than anything we've done before \" by Zayn Malik, as \" a lot of hard work \" by Payne, as \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 6.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 19,
        "original": "A Company, 2nd Engineer Combat Battalion, moved to the south side of the Yongsan @-@ Naktong River road ; D Company of the 2nd Engineer Battalion was on the north side of the road. Approximately 2",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 6.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 20,
        "original": "Once a pattern is identified, the storm features ( such as length and curvature of banding features ) are further analyzed to arrive at a particular T @-@ number.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 2.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 21,
        "original": "On 1 July 2015, Amos returned to Bolton Wanderers following his release from Manchester United, signing a four @-@ year contract with the club.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 2.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 22,
        "original": "All of the 17 confirmed colossal heads remain in Mexico. Two heads from San Lorenzo are on permanent display at the Museo Nacional de Antropolog\u00eda in Mexico City. Seven of the San Lorenzo heads are on display in the Museo de Antrop",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 13.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 23,
        "original": "Nero's father was described by Suetonius as a murderer and a cheat who was charged by Emperor Tiberius with treason, adultery and incest. Tiberius died, allowing him to escape these charges. Nero's father died",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.90 GiB memory in use. Process 121890 has 16.28 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 13.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 24,
        "original": "\" Kiss You \" was written by Kristoffer Fogelmark, Kristian Lundin, Albin Nedler, Savan Kotecha, Shellback, and its producers, Carl Falk and Rami Yacoub. Falk, Kotecha",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.90 GiB memory in use. Process 121890 has 16.28 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 13.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 25,
        "original": "Jinks and Cohen involved Ball throughout the film's development, including casting and director selection. The producers met with about 20 interested directors, several of whom were considered \" A @-@ list \" at the time. Ball was not keen on",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.90 GiB memory in use. Process 121890 has 16.28 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 13.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 26,
        "original": "The most basal group of temnospondyls is the superfamily Edopoidea. Edopoids have several primitive or plesiomorphic features, including a single occipital condyle and a bone called the intertemporal that is absent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.90 GiB memory in use. Process 121890 has 16.28 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 13.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 27,
        "original": "The multi @-@ genus approach is based solely on the structure of the male flowers ; no other characters could be consistently associated with one genus or another. Four of the genera \u2014 Attalea ( in a narrow sense ), Orbignya,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.89 GiB memory in use. Process 121890 has 16.29 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 13.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 28,
        "original": "The Talmud adds that the sage Reb Meir Baal HaNess, Rabbi Meir or Rabbi Meir Baal HaNes ( Rabbi Meir the miracle maker ) was a Jewish sage who lived in the time of the Mishna",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.31 GiB memory in use. Process 121765 has 15.90 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 3.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 29,
        "original": "The 3rd District ( 2015 population : 197 @,@ 242 ) covers Binondo, Quiapo, San Nicolas and Santa Cruz.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.31 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 3.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 30,
        "original": "On July 15, Lesnar was notified of a potential anti @-@ doping policy violation by the United States Anti @-@ Doping Agency ( USADA ) stemming from an undisclosed banned substance in an out @-@ of @-@",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.31 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 1.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 31,
        "original": "Note that in this case the Dvorak T @-@ number ( in this case T2.5 ) was simply used as a guide but other factors determined how the NHC decided to set the system's intensity.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.31 GiB memory in use. Process 121765 has 15.92 GiB memory in use. Process 121890 has 16.14 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 3.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 32,
        "original": "A second prequel, titled \" Vastra Investigates \", was released online on 17 December 2012. At the end of a case, Vastra and Jenny converse with an officer from Scotland Yard and apologise for Strax's violent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.31 GiB memory in use. Process 121765 has 16.00 GiB memory in use. Process 121890 has 16.06 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 3.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 33,
        "original": "Gore served as district attorney until 1796. His principal matter of concern was the enforcement of U.S. neutrality with respect to the French Revolutionary Wars. He attempted several times to prosecute the French consul in Boston, Antoine Duplaine, for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.31 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.09 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 3.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 34,
        "original": "The origins of Imagism are to be found in two poems, Autumn and A City Sunset by T. E. Hulme. These were published in January 1909 by the Poets'Club in London in a booklet called For Christmas MD",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.42 GiB memory in use. Process 121765 has 15.99 GiB memory in use. Process 121890 has 15.96 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.82 GiB is allocated by PyTorch, and 963.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 35,
        "original": "The route turns south at Cedar Street, following the residential street into downtown Akron. Here, NY 93 intersects with CR 573 ( John Street ) at a junction that was once the western terminus of NY 267. At this intersection, NY",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.45 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 15.98 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 36,
        "original": "UB @-@ 1 and the still incomplete UB @-@ 15 were sold to the Austria @-@ Hungary in February 1915 ; both were dismantled and shipped to Pola in May. After one cruise under the German flag",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.45 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 37,
        "original": "His father died around 740. Du Fu would have been allowed to enter the civil service because of his father's rank, but he is thought to have given up the privilege in favour of one of his half brothers. He spent the next four",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.45 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.96 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 3.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 38,
        "original": "Chinese sawmill owners at Sibu and Bintulu were instructed by the Japanese to produce timber for repairs at oil fields and ship building. During the Japanese occupation, sawmills at Bintulu produced a total of 4 @,@ 000",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.45 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 39,
        "original": "After NY 18, NY 93 curves to the southeast, serving another residential stretch ahead of a junction with Youngstown \u2013 Wilson Road ( CR 36 ) on the eastern edge of Towers Corners. After this intersection, the homes give way to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.45 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.01 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 40,
        "original": "The new United States Navy Zumwalt @-@ class guided missile destroyer has been described as bearing resemblance to ironclads.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.45 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.01 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 4.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 41,
        "original": "The current Mayor of Manila is Joseph Estrada, who served as the President of the Philippines from 1998 @-@ 2001. He is also the head of the executive department of the city. The legislative arm which is composed of six",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 15.98 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 15.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 42,
        "original": "As of July 2016, Lesnar's eldest son, Brock Jr. is ranked # 1 in Saskatchewan and # 4 in all of Canada in amateur wrestling.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 14.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 43,
        "original": "Typhoon Maemi formed on September 4 from the monsoon trough in the western Pacific Ocean. It slowly intensified into a tropical storm while moving northwestward, and Maemi became a typhoon on September 8. That day, it quickly intensified",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 16.07 GiB memory in use. Process 121890 has 15.83 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 13.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 44,
        "original": "HMS Warrior is today a fully restored museum ship in Portsmouth, England",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 16.00 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 14.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 45,
        "original": "Several agencies issue Dvorak intensity numbers for tropical cyclones and their precursors, including the National Hurricane Center's Tropical Analysis and Forecast Branch ( TAFB ), the NOAA / NESDIS Satellite Analysis Branch ( SAB ), and the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 16.00 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 46,
        "original": "The growth of Bintulu's population is shown below :",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 16.03 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 16.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 47,
        "original": "While passing northeast of the Philippines, the typhoon caused light damage in the archipelago. The eye crossed over Okinawa, where Etau left 166 @,@ 800 people without power and caused 10 injuries. Near where Etau",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 13.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 48,
        "original": "On the morning of September 1 the 1st and 2nd Regiments of the NK 9th Division, in their first offensive of the war, stood only a few miles short of Yongsan after a successful river crossing and penetration",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 13.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 49,
        "original": "For the French, the survival of the Corps Mortier seemed nothing short of a miracle. The remainder of Gazan's division crossed the river the next morning and eventually recuperated in Vienna, which the French acquired by deception later in the month.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 50,
        "original": "This heavy night and day battle cost the NK 2nd Division most of its remaining offensive strength. The medical officer of the NK 17th Regiment, 2nd Division, captured a few days later, said that the division evacuated about 300",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 51,
        "original": "The selectivity of some hydroxylations may be drastically improved in some cases with the addition of coordinating groups alpha to the oxaziridine ring as oxaziridines 3b and 3c in the table above. In these",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 52,
        "original": "Due to local conditions it was sometimes necessary for the Commission to deviate from its standard design. In places prone to extreme weather or earthquakes, such as Thailand and Turkey, stone @-@ faced pedestal markers are used instead of the normal headstones.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 53,
        "original": "Increasing wind shear weakened the convection, and Parma deteriorated into a severe tropical storm on October 26. The next day, it began moving westward while passing about 345 km ( 215 mi ) north of Wake Island. A large",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 54,
        "original": "In 49 AD, Claudius married a fourth time, to Nero's mother Agrippina, despite her being his niece. To aid Claudius politically, young Nero was adopted in 50 and took the name Nero Claudius Caesar Drus",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 55,
        "original": "Head VI was the first of Bacon's paintings to reference Vel\u00e1zquez, whose portrait of Pope Innocent X haunted him throughout his career and inspired his series of \" screaming popes \", a loose series of which there are around 45 surviving",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 56,
        "original": "Outside of Warren Corners, the route heads across rural areas along the Cambria \u2013 Lockport town line. It soon enters the small hamlet of Hickory Corners, where the road passes under Lower Mountain Road ( CR 902 ). Access",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 57,
        "original": "The rear turrets, the barbettes and their supporting structures were removed beginning in early 1943 and the openings in the middle deck were covered by 152 mm plates salvaged from the turret armour. All of the 14 cm guns were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 58,
        "original": "Samuel Devenny suffered a heart attack four days after his beating. On 17 July he suffered a further heart attack and died. Thousands attended his funeral, and the mood was sufficiently angry that it was clear the annual Apprentice Boys'parade,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.47 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.85 GiB is allocated by PyTorch, and 15.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 59,
        "original": "\" The Snowmen \" was initially released as a standalone on DVD and Blu @-@ ray in the UK and North America. It was later included as part of the DVD / Blu @-@ ray box set Doctor Who : The Complete Seventh Series",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.72 GiB memory in use. Process 121765 has 16.48 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 102.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 60,
        "original": "Stevens'teams are built around solid basketball fundamentals and good team work, rather than individual basketball skill. His teams are known for their defense, forcing opponents into uncharacteristic mistakes. The secret to basketball \u2013 and life \u2013 is \" just to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.20 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 2.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 61,
        "original": "The battles of the American Civil War and at Lissa were very influential on the designs and tactics of the ironclad fleets that followed. In particular, it taught a generation of naval officers the misleading lesson that ramming was the best way to sink",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 63.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 62,
        "original": "The Hustler was a major critical and popular success, gaining a reputation as a modern classic. Its exploration of winning, losing, and character garnered a number of major awards ; it is also credited with helping to spark a resurgence in the popularity of pool",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 63.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 63,
        "original": "The losses were staggering : Gazan lost close to 40 percent of his division to death and wounds. Aside from losing five guns, 47 officers and 895 men under his command were captured, bringing the loss of effectives closer to 60",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 63.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 64,
        "original": "At 21 : 00 the first shells of what proved to be a two @-@ hour North Korean artillery and mortar preparation against the American river positions of 2nd Platoon. As the barrage rolled on, North Korean infantry crossed the river",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 63.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 65,
        "original": "Lester becomes infatuated with Jane's vain friend, Angela Hayes, after seeing her perform a half @-@ time dance routine at a high school basketball game. He starts having sexual fantasies about Angela, in which red rose petals are a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 64.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 66,
        "original": "On 30 December, violence escalated \" an order of magnitude \" as militants entered Mogadishu, which was quickly enveloped by a general state of lawlessness. On 30 \u2013 31 December, diplomats, including many stationed in offices elsewhere",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 63.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 67,
        "original": "Dodd was selected to represent Australia at the 2012 Summer Paralympics in London in equestrian events with her horse Waikiwi. These Games were her first, and she was the youngest Australian equestrian competitor. A fund",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 63.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 68,
        "original": "In 65, Gaius Calpurnius Piso, a Roman statesman, organized a conspiracy against Nero with the help of Subrius Flavus and Sulpicius Asper, a tribune and a centurion",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 63.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 69,
        "original": "The cost to rebuild Rome was immense, requiring funds the state treasury did not have. Nero devalued the Roman currency for the first time in the Empire's history. He reduced the weight of the denarius from 84 per Roman pound to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 64.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 70,
        "original": "After the armistice of Cassibile ( 8 September ), the German @-@ allied Italian Social Republic launched at least two raids on Gibraltar : one on the night of 4 \u2013 5 June 1944 with ten SM.79",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 64.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 71,
        "original": "The German Imperial Navy stipulated that the submarines must be transportable by rail, which imposed a maximum diameter of 3 @.@ 15 metres ( 10 ft 4 in ). The rushed planning effort \u2014 which had been assigned the name \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 64.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 72,
        "original": "Oxaziridines with unsubstituted or acylated nitrogens are capable of nitrogen atom transfer, although this reactivity has received considerably less attention.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 2.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 73,
        "original": "Maslin felt that Mendes directed with \" terrific visual flair \", saying his minimalist style balanced \" the mordant and bright \" and that he evoked the \" delicate, eroticized power @-@ playing vignettes \" of his theater work",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 74,
        "original": "Temnospondyli became a commonly used name at the turn of the century. Paleontologists included both embolomeres and rhachitomes in the group. Cope's Ganocephala and Labyrinthodonta fell out",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 75,
        "original": "A new government center was to be built on the hills northeast of Manila, or what is now Quezon City. Several government agencies have set up their headquarters in Quezon City but several key government offices still reside in Manila. However, many of the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 76,
        "original": "During the last week of August, US troops on these hills could see minor North Korean activity across the river, which they thought was North Koreans organizing the high ground on the west side of the Naktong against a possible American attack. There were occasional",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 77,
        "original": "The removal of the secondary armament, the rear turrets and their supporting structures was generally compensated by the addition of the flight deck, hangar, AA guns and more fuel, and the metacentric height increased.23 metres ( 9 @",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 78,
        "original": "Manila was occupied by British forces for twenty months, from 1762 to 1764, and used as a base for an unsuccessful attempt to conquer the Philippines during the Seven Years'War. Eventually, the British withdrew from Manila as per agreements",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 79,
        "original": "Following the departure of Ben Foster from Manchester United to Birmingham City, United manager Alex Ferguson declared that Amos would be Manchester United's third @-@ choice goalkeeper for the 2010 \u2013 11 season behind Edwin van der Sar and Tomasz",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 80,
        "original": "The current court complex is located at Pisang Emas Road. It comprises the High Court, the Sessions Court, and the Magistrate Court. Bintulu also has Syariah Subordinate Court, located at Tanjung Kidurong,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 81,
        "original": "Among the Beats, Gary Snyder and Allen Ginsberg in particular were influenced by the Imagist emphasis on Chinese and Japanese poetry. William Carlos Williams was another who had a strong effect on the Beat poets, encouraging poets like Lew Welch and writing an introduction for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 82,
        "original": "When word of the disaster that had overtaken 1st Battalion reached regimental headquarters, Freeman obtained the release of G and F Companies from 2nd Division reserve and sent the former to help 1st Battalion and the latter on the southern road",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 83,
        "original": "A project is underway to photograph the graves of and memorials to all service personnel from 1914 to the present day and make the images available to the public. The work is being carried out by The War Graves Photographic Project in conjunction with the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 84,
        "original": "The first Type UB I to enter service was UB @-@ 10, which formed the nucleus of the Flanders Flotilla, on 27 March 1915. By the end of April five more Type UB I boats had become operational",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 85,
        "original": "The band was formed by vocalist Jared Gomes, formerly of The Clue, also known as \" M.C.U.D. \" ( MC Underdog ), and guitarist Wes Geer, who became friends amidst the Orange County hardcore punk scene. G",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 86,
        "original": "The episode saw several major design changes for the series. \" The Snowmen \" is the debut of a redesigned TARDIS interior, as well as a new title sequence and variation of the theme tune. The new title sequence features a brief glimpse of",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 48.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 87,
        "original": "Modern scholarship generally holds that, while the Senate and more well @-@ off individuals welcomed Nero's death, the general populace was \" loyal to the end and beyond, for Otho and Vitellius both thought it worthwhile to appeal to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 88,
        "original": "An article in The Times on 17 February 1919 by Rudyard Kipling carried the Commission's proposal to a wider audience and described what the graves would look like. The article entitled War Graves : Work of Imperial Commission : Mr.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 89,
        "original": "The Battle of D\u00fcrenstein ( also known as the Battle of D\u00fcrrenstein, Battle of D\u00fcrnstein and Battle of Diernstein ; German : Gefecht bei D\u00fcrrenstein ), on 11 November 1805",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 90,
        "original": "Critics classify Little Gidding as a poem of fire with an emphasis on purgation and the Pentecostal fire. The beginning of the poem discusses time and winter, with attention paid to the arrival of summer. The images of snow,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 48.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 91,
        "original": "The few Austrian corps not trapped at Ulm withdrew toward Vienna, with the French in close pursuit. A Russian army under Gen. Mikhail Kutuzov also maneuvered away from the French, withdrawing to the east. At the Ill river on 22",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 48.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 92,
        "original": "In the late 1970s and early 1980s Franklin A. Davis synthesized the first N @-@ sulfonyloxaziridines, which act exclusively as oxygen transfer reagents, and are the most predominantly used class of ox",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 48.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 93,
        "original": "The ability of the tympanum and stapes to effectively transmit vibrations is called impedance matching. Early tetrapods like temnospondyls have thick stapes with poor impedance matching, so it is now thought that they were not used for hearing",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 48.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 94,
        "original": "Almost all of Manila sits on top of centuries of prehistoric alluvial deposits built by the waters of the Pasig and on some land reclaimed from Manila Bay. Manila's land has been altered substantially by human intervention, with considerable land reclamation",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 95,
        "original": "Bacon said that chance played a significant role in his work, and that he often approached a canvas without having a clear idea of what might emerge. This was especially the case in the mid to late 1940s, a period when he was",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 48.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 96,
        "original": "The 4th District ( 2015 population : 265 @,@ 046 ) covers Sampaloc.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.35 GiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 97,
        "original": "Manila is a major publishing center in the Philippines. Manila Bulletin, the Philippines'largest broadsheet newspaper by circulation, is headquartered inside Intramuros. Other major publishing companies in the country like The Manila Times, The Philippine Star and Manila Standard Today",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 49.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 98,
        "original": "Tacitus was the son of a procurator, who married into the elite family of Agricola. He entered his political life as a senator after Nero's death and, by Tacitus'own admission, owed much to Nero's rivals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.35 GiB is allocated by PyTorch, and 3.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 99,
        "original": "At 22 : 30 the fog lifted and Kouma saw that a North Korean pontoon bridge was being laid across the river directly in front of his position. Kouma's four vehicles attacked this structure, and after about a minute of heavy",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 55.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      }
    ],
    "statistics": {
      "total_samples": 100,
      "successful": 0,
      "success_rate": 0.0
    }
  },
  {
    "layer": 7,
    "samples": [
      {
        "sample_idx": 0,
        "original": "The history of Nero's reign is problematic in that no historical sources survived that were contemporary with Nero. These first histories at one time did exist and were described as biased and fantastical, either overly critical or praising of Nero. The original sources were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.14 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 1,
        "original": "Ironclads were designed for several roles, including as high seas battleships, coastal defense ships, and long @-@ range cruisers. The rapid evolution of warship design in the late 19th century transformed the ironclad from a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.14 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 2,
        "original": "The track became the group's sixth top @-@ ten hit in Ireland and the United Kingdom, while attaining top @-@ forty positions in both Belgian territories ( Flanders and Wallonia ), as well as in Australia, Canada,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.15 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.36 GiB is allocated by PyTorch, and 7.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 3,
        "original": "The band began touring in support of the album prior to its release, initiating touring with several free shows in the US. Followed by multiple appearances at festivals in Europe. They then joined Korn for their 2006 edition of Family Values Tour across",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.15 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 4,
        "original": "Imagism was a movement in early 20th @-@ century Anglo @-@ American poetry that favored precision of imagery and clear, sharp language.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.96 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 14.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 5,
        "original": "Kershaw finished 2012 with a 14 \u2013 9 record, a 2 @.@ 53 ERA ( leading the league ), 229 strikeouts, and 2272 \u2044 3 innings pitched, coming second in both categories",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 27.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 6,
        "original": "NY 31B began at an intersection with its parent route, NY 31, in the Cayuga County village of Weedsport. The highway went eastward, intersecting with NY 34 less than 0 @.@ 1 miles (",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 7,
        "original": "The unsuitability of unarmored iron for warship hulls meant that iron was only adopted as a building material for battleships when protected by armor. However, iron gave the naval architect many advantages. Iron allowed larger ships and more flexible design",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 8,
        "original": "Both the Provisional and Official IRA stepped up attacks after Bloody Sunday, with the tacit support of the residents. Local feelings changed, however, with the killing of Ranger William Best by the Official IRA. Best was a 19 @-@ year",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 9,
        "original": "On October 27, 2000, Gomes was arrested for possession of marijuana while the band was performing in Waterbury, Connecticut. He was released on a US $ 1 @,@ 500 bond. In 2001, Hed PE",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.25 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 10,
        "original": "The headquarters of the Philippine Coast Guard is located at the South Harbor in Port Area near Intramuros and Ermita. The Philippine Navy on the other hand has its headquarters in Naval Station Jose Andrada located along Roxas Boulevard in Malate.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.25 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 11,
        "original": "It was announced in March 2006 that Stone Sour's second album, which was tentatively titled \" Come What May, \" would be released on July 18, 2006. However, the release date for the album was pushed back",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.25 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 27.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 12,
        "original": "The Mediterranean U @-@ boat Campaign lasted approximately from 21 September 1941 to May 1944. The Kriegsmarine tried to isolate Gibraltar, Malta, and Suez and disrupt Britain's trade routes. More than sixty U",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 27.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 13,
        "original": "A neutron spectrometer on board the Lunar Prospector spacecraft detected enhanced concentrations of hydrogen close to the northern and southern lunar poles, including the crater Shackleton. At the end of this mission in July 1999, the spacecraft was crashed into the nearby",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 14,
        "original": "That same afternoon, the North Koreans sent an American prisoner up the hill to Schmitt with the message, \" You have one hour to surrender or be blown to pieces. \" Failing in frontal infantry attack to reduce the little defending force, the North",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 15,
        "original": "Although Gore was well received by the British establishment, the work suffered from what Gore called a \" tediousness of process \", and he considered requesting a transfer in 1798. In 1800 it ground to a halt because another board established by",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 27.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 16,
        "original": "On December 15, 2011, Lesnar was charged with hunting infractions on a trip to Alberta on November 19, 2010. Two charges were dropped, but Lesnar pleaded guilty to the charge of improper tagging of an animal",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 17,
        "original": "Carl Falk \u2014 writing, production, programming, instruments, guitar, background vocals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 15.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 18,
        "original": "Shot by November 2012, the music video was characterised, in several MTV News interviews, as \" bigger than anything we've done before \" by Zayn Malik, as \" a lot of hard work \" by Payne, as \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 27.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 19,
        "original": "A Company, 2nd Engineer Combat Battalion, moved to the south side of the Yongsan @-@ Naktong River road ; D Company of the 2nd Engineer Battalion was on the north side of the road. Approximately 2",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 20,
        "original": "Once a pattern is identified, the storm features ( such as length and curvature of banding features ) are further analyzed to arrive at a particular T @-@ number.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.12 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.92 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 12.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 21,
        "original": "On 1 July 2015, Amos returned to Bolton Wanderers following his release from Manchester United, signing a four @-@ year contract with the club.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.86 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 22,
        "original": "All of the 17 confirmed colossal heads remain in Mexico. Two heads from San Lorenzo are on permanent display at the Museo Nacional de Antropolog\u00eda in Mexico City. Seven of the San Lorenzo heads are on display in the Museo de Antrop",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.86 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 23,
        "original": "Nero's father was described by Suetonius as a murderer and a cheat who was charged by Emperor Tiberius with treason, adultery and incest. Tiberius died, allowing him to escape these charges. Nero's father died",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 18.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 24,
        "original": "\" Kiss You \" was written by Kristoffer Fogelmark, Kristian Lundin, Albin Nedler, Savan Kotecha, Shellback, and its producers, Carl Falk and Rami Yacoub. Falk, Kotecha",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 25,
        "original": "Jinks and Cohen involved Ball throughout the film's development, including casting and director selection. The producers met with about 20 interested directors, several of whom were considered \" A @-@ list \" at the time. Ball was not keen on",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 27.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 26,
        "original": "The most basal group of temnospondyls is the superfamily Edopoidea. Edopoids have several primitive or plesiomorphic features, including a single occipital condyle and a bone called the intertemporal that is absent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 27,
        "original": "The multi @-@ genus approach is based solely on the structure of the male flowers ; no other characters could be consistently associated with one genus or another. Four of the genera \u2014 Attalea ( in a narrow sense ), Orbignya,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 27.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 28,
        "original": "The Talmud adds that the sage Reb Meir Baal HaNess, Rabbi Meir or Rabbi Meir Baal HaNes ( Rabbi Meir the miracle maker ) was a Jewish sage who lived in the time of the Mishna",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 25.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 29,
        "original": "The 3rd District ( 2015 population : 197 @,@ 242 ) covers Binondo, Quiapo, San Nicolas and Santa Cruz.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.09 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.93 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 6.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 30,
        "original": "On July 15, Lesnar was notified of a potential anti @-@ doping policy violation by the United States Anti @-@ Doping Agency ( USADA ) stemming from an undisclosed banned substance in an out @-@ of @-@",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.09 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 23.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 31,
        "original": "Note that in this case the Dvorak T @-@ number ( in this case T2.5 ) was simply used as a guide but other factors determined how the NHC decided to set the system's intensity.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.10 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 10.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 32,
        "original": "A second prequel, titled \" Vastra Investigates \", was released online on 17 December 2012. At the end of a case, Vastra and Jenny converse with an officer from Scotland Yard and apologise for Strax's violent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.10 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 7.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 33,
        "original": "Gore served as district attorney until 1796. His principal matter of concern was the enforcement of U.S. neutrality with respect to the French Revolutionary Wars. He attempted several times to prosecute the French consul in Boston, Antoine Duplaine, for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.99 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 25.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 34,
        "original": "The origins of Imagism are to be found in two poems, Autumn and A City Sunset by T. E. Hulme. These were published in January 1909 by the Poets'Club in London in a booklet called For Christmas MD",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 16.34 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 25.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 35,
        "original": "The route turns south at Cedar Street, following the residential street into downtown Akron. Here, NY 93 intersects with CR 573 ( John Street ) at a junction that was once the western terminus of NY 267. At this intersection, NY",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 25.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 36,
        "original": "UB @-@ 1 and the still incomplete UB @-@ 15 were sold to the Austria @-@ Hungary in February 1915 ; both were dismantled and shipped to Pola in May. After one cruise under the German flag",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 25.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 37,
        "original": "His father died around 740. Du Fu would have been allowed to enter the civil service because of his father's rank, but he is thought to have given up the privilege in favour of one of his half brothers. He spent the next four",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 16.34 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 27.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 38,
        "original": "Chinese sawmill owners at Sibu and Bintulu were instructed by the Japanese to produce timber for repairs at oil fields and ship building. During the Japanese occupation, sawmills at Bintulu produced a total of 4 @,@ 000",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 25.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 39,
        "original": "After NY 18, NY 93 curves to the southeast, serving another residential stretch ahead of a junction with Youngstown \u2013 Wilson Road ( CR 36 ) on the eastern edge of Towers Corners. After this intersection, the homes give way to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 25.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 40,
        "original": "The new United States Navy Zumwalt @-@ class guided missile destroyer has been described as bearing resemblance to ironclads.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.14 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 20.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 41,
        "original": "The current Mayor of Manila is Joseph Estrada, who served as the President of the Philippines from 1998 @-@ 2001. He is also the head of the executive department of the city. The legislative arm which is composed of six",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 16.33 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 25.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 42,
        "original": "As of July 2016, Lesnar's eldest son, Brock Jr. is ranked # 1 in Saskatchewan and # 4 in all of Canada in amateur wrestling.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.44 GiB memory in use. Process 121890 has 15.93 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 7.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 43,
        "original": "Typhoon Maemi formed on September 4 from the monsoon trough in the western Pacific Ocean. It slowly intensified into a tropical storm while moving northwestward, and Maemi became a typhoon on September 8. That day, it quickly intensified",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.44 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 44,
        "original": "HMS Warrior is today a fully restored museum ship in Portsmouth, England",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.44 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 45,
        "original": "Several agencies issue Dvorak intensity numbers for tropical cyclones and their precursors, including the National Hurricane Center's Tropical Analysis and Forecast Branch ( TAFB ), the NOAA / NESDIS Satellite Analysis Branch ( SAB ), and the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.01 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.86 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 7.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 46,
        "original": "The growth of Bintulu's population is shown below :",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.86 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 3.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 47,
        "original": "While passing northeast of the Philippines, the typhoon caused light damage in the archipelago. The eye crossed over Okinawa, where Etau left 166 @,@ 800 people without power and caused 10 injuries. Near where Etau",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 59.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 48,
        "original": "On the morning of September 1 the 1st and 2nd Regiments of the NK 9th Division, in their first offensive of the war, stood only a few miles short of Yongsan after a successful river crossing and penetration",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 59.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 49,
        "original": "For the French, the survival of the Corps Mortier seemed nothing short of a miracle. The remainder of Gazan's division crossed the river the next morning and eventually recuperated in Vienna, which the French acquired by deception later in the month.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 67.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 50,
        "original": "This heavy night and day battle cost the NK 2nd Division most of its remaining offensive strength. The medical officer of the NK 17th Regiment, 2nd Division, captured a few days later, said that the division evacuated about 300",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 51,
        "original": "The selectivity of some hydroxylations may be drastically improved in some cases with the addition of coordinating groups alpha to the oxaziridine ring as oxaziridines 3b and 3c in the table above. In these",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 52,
        "original": "Due to local conditions it was sometimes necessary for the Commission to deviate from its standard design. In places prone to extreme weather or earthquakes, such as Thailand and Turkey, stone @-@ faced pedestal markers are used instead of the normal headstones.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 53,
        "original": "Increasing wind shear weakened the convection, and Parma deteriorated into a severe tropical storm on October 26. The next day, it began moving westward while passing about 345 km ( 215 mi ) north of Wake Island. A large",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 54,
        "original": "In 49 AD, Claudius married a fourth time, to Nero's mother Agrippina, despite her being his niece. To aid Claudius politically, young Nero was adopted in 50 and took the name Nero Claudius Caesar Drus",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 67.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 55,
        "original": "Head VI was the first of Bacon's paintings to reference Vel\u00e1zquez, whose portrait of Pope Innocent X haunted him throughout his career and inspired his series of \" screaming popes \", a loose series of which there are around 45 surviving",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 7.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 56,
        "original": "Outside of Warren Corners, the route heads across rural areas along the Cambria \u2013 Lockport town line. It soon enters the small hamlet of Hickory Corners, where the road passes under Lower Mountain Road ( CR 902 ). Access",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 67.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 57,
        "original": "The rear turrets, the barbettes and their supporting structures were removed beginning in early 1943 and the openings in the middle deck were covered by 152 mm plates salvaged from the turret armour. All of the 14 cm guns were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 58,
        "original": "Samuel Devenny suffered a heart attack four days after his beating. On 17 July he suffered a further heart attack and died. Thousands attended his funeral, and the mood was sufficiently angry that it was clear the annual Apprentice Boys'parade,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 58.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 59,
        "original": "\" The Snowmen \" was initially released as a standalone on DVD and Blu @-@ ray in the UK and North America. It was later included as part of the DVD / Blu @-@ ray box set Doctor Who : The Complete Seventh Series",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 60,
        "original": "Stevens'teams are built around solid basketball fundamentals and good team work, rather than individual basketball skill. His teams are known for their defense, forcing opponents into uncharacteristic mistakes. The secret to basketball \u2013 and life \u2013 is \" just to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 58.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 61,
        "original": "The battles of the American Civil War and at Lissa were very influential on the designs and tactics of the ironclad fleets that followed. In particular, it taught a generation of naval officers the misleading lesson that ramming was the best way to sink",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 62,
        "original": "The Hustler was a major critical and popular success, gaining a reputation as a modern classic. Its exploration of winning, losing, and character garnered a number of major awards ; it is also credited with helping to spark a resurgence in the popularity of pool",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 63,
        "original": "The losses were staggering : Gazan lost close to 40 percent of his division to death and wounds. Aside from losing five guns, 47 officers and 895 men under his command were captured, bringing the loss of effectives closer to 60",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 64,
        "original": "At 21 : 00 the first shells of what proved to be a two @-@ hour North Korean artillery and mortar preparation against the American river positions of 2nd Platoon. As the barrage rolled on, North Korean infantry crossed the river",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 65,
        "original": "Lester becomes infatuated with Jane's vain friend, Angela Hayes, after seeing her perform a half @-@ time dance routine at a high school basketball game. He starts having sexual fantasies about Angela, in which red rose petals are a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 67.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 66,
        "original": "On 30 December, violence escalated \" an order of magnitude \" as militants entered Mogadishu, which was quickly enveloped by a general state of lawlessness. On 30 \u2013 31 December, diplomats, including many stationed in offices elsewhere",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 67,
        "original": "Dodd was selected to represent Australia at the 2012 Summer Paralympics in London in equestrian events with her horse Waikiwi. These Games were her first, and she was the youngest Australian equestrian competitor. A fund",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 68,
        "original": "In 65, Gaius Calpurnius Piso, a Roman statesman, organized a conspiracy against Nero with the help of Subrius Flavus and Sulpicius Asper, a tribune and a centurion",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 64.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 69,
        "original": "The cost to rebuild Rome was immense, requiring funds the state treasury did not have. Nero devalued the Roman currency for the first time in the Empire's history. He reduced the weight of the denarius from 84 per Roman pound to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.01 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.83 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 38.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 70,
        "original": "After the armistice of Cassibile ( 8 September ), the German @-@ allied Italian Social Republic launched at least two raids on Gibraltar : one on the night of 4 \u2013 5 June 1944 with ten SM.79",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.01 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.83 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 71,
        "original": "The German Imperial Navy stipulated that the submarines must be transportable by rail, which imposed a maximum diameter of 3 @.@ 15 metres ( 10 ft 4 in ). The rushed planning effort \u2014 which had been assigned the name \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.83 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 71.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 72,
        "original": "Oxaziridines with unsubstituted or acylated nitrogens are capable of nitrogen atom transfer, although this reactivity has received considerably less attention.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 142.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 73,
        "original": "Maslin felt that Mendes directed with \" terrific visual flair \", saying his minimalist style balanced \" the mordant and bright \" and that he evoked the \" delicate, eroticized power @-@ playing vignettes \" of his theater work",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 51.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 74,
        "original": "Temnospondyli became a commonly used name at the turn of the century. Paleontologists included both embolomeres and rhachitomes in the group. Cope's Ganocephala and Labyrinthodonta fell out",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 51.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 75,
        "original": "A new government center was to be built on the hills northeast of Manila, or what is now Quezon City. Several government agencies have set up their headquarters in Quezon City but several key government offices still reside in Manila. However, many of the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 47.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 76,
        "original": "During the last week of August, US troops on these hills could see minor North Korean activity across the river, which they thought was North Koreans organizing the high ground on the west side of the Naktong against a possible American attack. There were occasional",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 47.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 77,
        "original": "The removal of the secondary armament, the rear turrets and their supporting structures was generally compensated by the addition of the flight deck, hangar, AA guns and more fuel, and the metacentric height increased.23 metres ( 9 @",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 78,
        "original": "Manila was occupied by British forces for twenty months, from 1762 to 1764, and used as a base for an unsuccessful attempt to conquer the Philippines during the Seven Years'War. Eventually, the British withdrew from Manila as per agreements",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 79,
        "original": "Following the departure of Ben Foster from Manchester United to Birmingham City, United manager Alex Ferguson declared that Amos would be Manchester United's third @-@ choice goalkeeper for the 2010 \u2013 11 season behind Edwin van der Sar and Tomasz",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 51.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 80,
        "original": "The current court complex is located at Pisang Emas Road. It comprises the High Court, the Sessions Court, and the Magistrate Court. Bintulu also has Syariah Subordinate Court, located at Tanjung Kidurong,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 81,
        "original": "Among the Beats, Gary Snyder and Allen Ginsberg in particular were influenced by the Imagist emphasis on Chinese and Japanese poetry. William Carlos Williams was another who had a strong effect on the Beat poets, encouraging poets like Lew Welch and writing an introduction for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 82,
        "original": "When word of the disaster that had overtaken 1st Battalion reached regimental headquarters, Freeman obtained the release of G and F Companies from 2nd Division reserve and sent the former to help 1st Battalion and the latter on the southern road",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 83,
        "original": "A project is underway to photograph the graves of and memorials to all service personnel from 1914 to the present day and make the images available to the public. The work is being carried out by The War Graves Photographic Project in conjunction with the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 84,
        "original": "The first Type UB I to enter service was UB @-@ 10, which formed the nucleus of the Flanders Flotilla, on 27 March 1915. By the end of April five more Type UB I boats had become operational",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 85,
        "original": "The band was formed by vocalist Jared Gomes, formerly of The Clue, also known as \" M.C.U.D. \" ( MC Underdog ), and guitarist Wes Geer, who became friends amidst the Orange County hardcore punk scene. G",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 86,
        "original": "The episode saw several major design changes for the series. \" The Snowmen \" is the debut of a redesigned TARDIS interior, as well as a new title sequence and variation of the theme tune. The new title sequence features a brief glimpse of",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.93 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 48.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 87,
        "original": "Modern scholarship generally holds that, while the Senate and more well @-@ off individuals welcomed Nero's death, the general populace was \" loyal to the end and beyond, for Otho and Vitellius both thought it worthwhile to appeal to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.93 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 54.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 88,
        "original": "An article in The Times on 17 February 1919 by Rudyard Kipling carried the Commission's proposal to a wider audience and described what the graves would look like. The article entitled War Graves : Work of Imperial Commission : Mr.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.92 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 54.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 89,
        "original": "The Battle of D\u00fcrenstein ( also known as the Battle of D\u00fcrrenstein, Battle of D\u00fcrnstein and Battle of Diernstein ; German : Gefecht bei D\u00fcrrenstein ), on 11 November 1805",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 54.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 90,
        "original": "Critics classify Little Gidding as a poem of fire with an emphasis on purgation and the Pentecostal fire. The beginning of the poem discusses time and winter, with attention paid to the arrival of summer. The images of snow,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 91,
        "original": "The few Austrian corps not trapped at Ulm withdrew toward Vienna, with the French in close pursuit. A Russian army under Gen. Mikhail Kutuzov also maneuvered away from the French, withdrawing to the east. At the Ill river on 22",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 92,
        "original": "In the late 1970s and early 1980s Franklin A. Davis synthesized the first N @-@ sulfonyloxaziridines, which act exclusively as oxygen transfer reagents, and are the most predominantly used class of ox",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 93,
        "original": "The ability of the tympanum and stapes to effectively transmit vibrations is called impedance matching. Early tetrapods like temnospondyls have thick stapes with poor impedance matching, so it is now thought that they were not used for hearing",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 94,
        "original": "Almost all of Manila sits on top of centuries of prehistoric alluvial deposits built by the waters of the Pasig and on some land reclaimed from Manila Bay. Manila's land has been altered substantially by human intervention, with considerable land reclamation",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 54.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 95,
        "original": "Bacon said that chance played a significant role in his work, and that he often approached a canvas without having a clear idea of what might emerge. This was especially the case in the mid to late 1940s, a period when he was",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 96,
        "original": "The 4th District ( 2015 population : 265 @,@ 046 ) covers Sampaloc.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 15.90 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 5.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 97,
        "original": "Manila is a major publishing center in the Philippines. Manila Bulletin, the Philippines'largest broadsheet newspaper by circulation, is headquartered inside Intramuros. Other major publishing companies in the country like The Manila Times, The Philippine Star and Manila Standard Today",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 52.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 98,
        "original": "Tacitus was the son of a procurator, who married into the elite family of Agricola. He entered his political life as a senator after Nero's death and, by Tacitus'own admission, owed much to Nero's rivals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 24.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 99,
        "original": "At 22 : 30 the fog lifted and Kouma saw that a North Korean pontoon bridge was being laid across the river directly in front of his position. Kouma's four vehicles attacked this structure, and after about a minute of heavy",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 56.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      }
    ],
    "statistics": {
      "total_samples": 100,
      "successful": 0,
      "success_rate": 0.0
    }
  },
  {
    "layer": 15,
    "samples": [
      {
        "sample_idx": 0,
        "original": "The history of Nero's reign is problematic in that no historical sources survived that were contemporary with Nero. These first histories at one time did exist and were described as biased and fantastical, either overly critical or praising of Nero. The original sources were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 56.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 1,
        "original": "Ironclads were designed for several roles, including as high seas battleships, coastal defense ships, and long @-@ range cruisers. The rapid evolution of warship design in the late 19th century transformed the ironclad from a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 56.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 2,
        "original": "The track became the group's sixth top @-@ ten hit in Ireland and the United Kingdom, while attaining top @-@ forty positions in both Belgian territories ( Flanders and Wallonia ), as well as in Australia, Canada,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 24.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 3,
        "original": "The band began touring in support of the album prior to its release, initiating touring with several free shows in the US. Followed by multiple appearances at festivals in Europe. They then joined Korn for their 2006 edition of Family Values Tour across",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 56.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 4,
        "original": "Imagism was a movement in early 20th @-@ century Anglo @-@ American poetry that favored precision of imagery and clear, sharp language.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.97 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 128.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 5,
        "original": "Kershaw finished 2012 with a 14 \u2013 9 record, a 2 @.@ 53 ERA ( leading the league ), 229 strikeouts, and 2272 \u2044 3 innings pitched, coming second in both categories",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.97 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 6,
        "original": "NY 31B began at an intersection with its parent route, NY 31, in the Cayuga County village of Weedsport. The highway went eastward, intersecting with NY 34 less than 0 @.@ 1 miles (",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.97 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 7,
        "original": "The unsuitability of unarmored iron for warship hulls meant that iron was only adopted as a building material for battleships when protected by armor. However, iron gave the naval architect many advantages. Iron allowed larger ships and more flexible design",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.97 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 8,
        "original": "Both the Provisional and Official IRA stepped up attacks after Bloody Sunday, with the tacit support of the residents. Local feelings changed, however, with the killing of Ranger William Best by the Official IRA. Best was a 19 @-@ year",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.96 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 9,
        "original": "On October 27, 2000, Gomes was arrested for possession of marijuana while the band was performing in Waterbury, Connecticut. He was released on a US $ 1 @,@ 500 bond. In 2001, Hed PE",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.96 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 10,
        "original": "The headquarters of the Philippine Coast Guard is located at the South Harbor in Port Area near Intramuros and Ermita. The Philippine Navy on the other hand has its headquarters in Naval Station Jose Andrada located along Roxas Boulevard in Malate.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.97 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 11,
        "original": "It was announced in March 2006 that Stone Sour's second album, which was tentatively titled \" Come What May, \" would be released on July 18, 2006. However, the release date for the album was pushed back",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.93 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 54.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 12,
        "original": "The Mediterranean U @-@ boat Campaign lasted approximately from 21 September 1941 to May 1944. The Kriegsmarine tried to isolate Gibraltar, Malta, and Suez and disrupt Britain's trade routes. More than sixty U",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 55.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 13,
        "original": "A neutron spectrometer on board the Lunar Prospector spacecraft detected enhanced concentrations of hydrogen close to the northern and southern lunar poles, including the crater Shackleton. At the end of this mission in July 1999, the spacecraft was crashed into the nearby",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 49.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 14,
        "original": "That same afternoon, the North Koreans sent an American prisoner up the hill to Schmitt with the message, \" You have one hour to surrender or be blown to pieces. \" Failing in frontal infantry attack to reduce the little defending force, the North",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 15,
        "original": "Although Gore was well received by the British establishment, the work suffered from what Gore called a \" tediousness of process \", and he considered requesting a transfer in 1798. In 1800 it ground to a halt because another board established by",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 56.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 16,
        "original": "On December 15, 2011, Lesnar was charged with hunting infractions on a trip to Alberta on November 19, 2010. Two charges were dropped, but Lesnar pleaded guilty to the charge of improper tagging of an animal",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 49.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 17,
        "original": "Carl Falk \u2014 writing, production, programming, instruments, guitar, background vocals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.89 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.36 GiB is allocated by PyTorch, and 6.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 18,
        "original": "Shot by November 2012, the music video was characterised, in several MTV News interviews, as \" bigger than anything we've done before \" by Zayn Malik, as \" a lot of hard work \" by Payne, as \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 55.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 19,
        "original": "A Company, 2nd Engineer Combat Battalion, moved to the south side of the Yongsan @-@ Naktong River road ; D Company of the 2nd Engineer Battalion was on the north side of the road. Approximately 2",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 55.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 20,
        "original": "Once a pattern is identified, the storm features ( such as length and curvature of banding features ) are further analyzed to arrive at a particular T @-@ number.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 142.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 21,
        "original": "On 1 July 2015, Amos returned to Bolton Wanderers following his release from Manchester United, signing a four @-@ year contract with the club.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 142.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 22,
        "original": "All of the 17 confirmed colossal heads remain in Mexico. Two heads from San Lorenzo are on permanent display at the Museo Nacional de Antropolog\u00eda in Mexico City. Seven of the San Lorenzo heads are on display in the Museo de Antrop",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 54.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 23,
        "original": "Nero's father was described by Suetonius as a murderer and a cheat who was charged by Emperor Tiberius with treason, adultery and incest. Tiberius died, allowing him to escape these charges. Nero's father died",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 28.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 24,
        "original": "\" Kiss You \" was written by Kristoffer Fogelmark, Kristian Lundin, Albin Nedler, Savan Kotecha, Shellback, and its producers, Carl Falk and Rami Yacoub. Falk, Kotecha",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 54.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 25,
        "original": "Jinks and Cohen involved Ball throughout the film's development, including casting and director selection. The producers met with about 20 interested directors, several of whom were considered \" A @-@ list \" at the time. Ball was not keen on",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.30 GiB is allocated by PyTorch, and 60.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 26,
        "original": "The most basal group of temnospondyls is the superfamily Edopoidea. Edopoids have several primitive or plesiomorphic features, including a single occipital condyle and a bone called the intertemporal that is absent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 54.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 27,
        "original": "The multi @-@ genus approach is based solely on the structure of the male flowers ; no other characters could be consistently associated with one genus or another. Four of the genera \u2014 Attalea ( in a narrow sense ), Orbignya,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.30 GiB is allocated by PyTorch, and 60.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 28,
        "original": "The Talmud adds that the sage Reb Meir Baal HaNess, Rabbi Meir or Rabbi Meir Baal HaNes ( Rabbi Meir the miracle maker ) was a Jewish sage who lived in the time of the Mishna",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 16.50 GiB memory in use. Process 121890 has 15.90 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 54.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 29,
        "original": "The 3rd District ( 2015 population : 197 @,@ 242 ) covers Binondo, Quiapo, San Nicolas and Santa Cruz.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.94 GiB memory in use. Process 121765 has 16.52 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 16.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 30,
        "original": "On July 15, Lesnar was notified of a potential anti @-@ doping policy violation by the United States Anti @-@ Doping Agency ( USADA ) stemming from an undisclosed banned substance in an out @-@ of @-@",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.95 GiB memory in use. Process 121765 has 16.51 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 66.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 31,
        "original": "Note that in this case the Dvorak T @-@ number ( in this case T2.5 ) was simply used as a guide but other factors determined how the NHC decided to set the system's intensity.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 15.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 32,
        "original": "A second prequel, titled \" Vastra Investigates \", was released online on 17 December 2012. At the end of a case, Vastra and Jenny converse with an officer from Scotland Yard and apologise for Strax's violent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 33,
        "original": "Gore served as district attorney until 1796. His principal matter of concern was the enforcement of U.S. neutrality with respect to the French Revolutionary Wars. He attempted several times to prosecute the French consul in Boston, Antoine Duplaine, for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 48.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 34,
        "original": "The origins of Imagism are to be found in two poems, Autumn and A City Sunset by T. E. Hulme. These were published in January 1909 by the Poets'Club in London in a booklet called For Christmas MD",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 16.53 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 52.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 35,
        "original": "The route turns south at Cedar Street, following the residential street into downtown Akron. Here, NY 93 intersects with CR 573 ( John Street ) at a junction that was once the western terminus of NY 267. At this intersection, NY",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.01 GiB memory in use. Process 121765 has 16.05 GiB memory in use. Process 121890 has 16.31 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.35 GiB is allocated by PyTorch, and 52.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 36,
        "original": "UB @-@ 1 and the still incomplete UB @-@ 15 were sold to the Austria @-@ Hungary in February 1915 ; both were dismantled and shipped to Pola in May. After one cruise under the German flag",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.03 GiB memory in use. Process 121765 has 16.00 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 63.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 37,
        "original": "His father died around 740. Du Fu would have been allowed to enter the civil service because of his father's rank, but he is thought to have given up the privilege in favour of one of his half brothers. He spent the next four",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.04 GiB memory in use. Process 121765 has 15.99 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 53.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 38,
        "original": "Chinese sawmill owners at Sibu and Bintulu were instructed by the Japanese to produce timber for repairs at oil fields and ship building. During the Japanese occupation, sawmills at Bintulu produced a total of 4 @,@ 000",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.04 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 51.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 39,
        "original": "After NY 18, NY 93 curves to the southeast, serving another residential stretch ahead of a junction with Youngstown \u2013 Wilson Road ( CR 36 ) on the eastern edge of Towers Corners. After this intersection, the homes give way to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.99 GiB memory in use. Process 121765 has 16.03 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 54.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 40,
        "original": "The new United States Navy Zumwalt @-@ class guided missile destroyer has been described as bearing resemblance to ironclads.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.04 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 10.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 41,
        "original": "The current Mayor of Manila is Joseph Estrada, who served as the President of the Philippines from 1998 @-@ 2001. He is also the head of the executive department of the city. The legislative arm which is composed of six",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.01 GiB memory in use. Process 121765 has 16.05 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.35 GiB is allocated by PyTorch, and 52.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 42,
        "original": "As of July 2016, Lesnar's eldest son, Brock Jr. is ranked # 1 in Saskatchewan and # 4 in all of Canada in amateur wrestling.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 16.06 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.35 GiB is allocated by PyTorch, and 21.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 43,
        "original": "Typhoon Maemi formed on September 4 from the monsoon trough in the western Pacific Ocean. It slowly intensified into a tropical storm while moving northwestward, and Maemi became a typhoon on September 8. That day, it quickly intensified",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.01 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.35 GiB is allocated by PyTorch, and 52.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 44,
        "original": "HMS Warrior is today a fully restored museum ship in Portsmouth, England",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.02 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 11.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 45,
        "original": "Several agencies issue Dvorak intensity numbers for tropical cyclones and their precursors, including the National Hurricane Center's Tropical Analysis and Forecast Branch ( TAFB ), the NOAA / NESDIS Satellite Analysis Branch ( SAB ), and the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 32.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 46,
        "original": "The growth of Bintulu's population is shown below :",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.36 GiB is allocated by PyTorch, and 7.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 47,
        "original": "While passing northeast of the Philippines, the typhoon caused light damage in the archipelago. The eye crossed over Okinawa, where Etau left 166 @,@ 800 people without power and caused 10 injuries. Near where Etau",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 61.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 48,
        "original": "On the morning of September 1 the 1st and 2nd Regiments of the NK 9th Division, in their first offensive of the war, stood only a few miles short of Yongsan after a successful river crossing and penetration",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 61.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 49,
        "original": "For the French, the survival of the Corps Mortier seemed nothing short of a miracle. The remainder of Gazan's division crossed the river the next morning and eventually recuperated in Vienna, which the French acquired by deception later in the month.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 60.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 50,
        "original": "This heavy night and day battle cost the NK 2nd Division most of its remaining offensive strength. The medical officer of the NK 17th Regiment, 2nd Division, captured a few days later, said that the division evacuated about 300",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 55.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 51,
        "original": "The selectivity of some hydroxylations may be drastically improved in some cases with the addition of coordinating groups alpha to the oxaziridine ring as oxaziridines 3b and 3c in the table above. In these",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 55.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 52,
        "original": "Due to local conditions it was sometimes necessary for the Commission to deviate from its standard design. In places prone to extreme weather or earthquakes, such as Thailand and Turkey, stone @-@ faced pedestal markers are used instead of the normal headstones.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 55.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 53,
        "original": "Increasing wind shear weakened the convection, and Parma deteriorated into a severe tropical storm on October 26. The next day, it began moving westward while passing about 345 km ( 215 mi ) north of Wake Island. A large",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 55.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 54,
        "original": "In 49 AD, Claudius married a fourth time, to Nero's mother Agrippina, despite her being his niece. To aid Claudius politically, young Nero was adopted in 50 and took the name Nero Claudius Caesar Drus",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 56.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 55,
        "original": "Head VI was the first of Bacon's paintings to reference Vel\u00e1zquez, whose portrait of Pope Innocent X haunted him throughout his career and inspired his series of \" screaming popes \", a loose series of which there are around 45 surviving",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.35 GiB is allocated by PyTorch, and 14.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 56,
        "original": "Outside of Warren Corners, the route heads across rural areas along the Cambria \u2013 Lockport town line. It soon enters the small hamlet of Hickory Corners, where the road passes under Lower Mountain Road ( CR 902 ). Access",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.30 GiB is allocated by PyTorch, and 57.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 57,
        "original": "The rear turrets, the barbettes and their supporting structures were removed beginning in early 1943 and the openings in the middle deck were covered by 152 mm plates salvaged from the turret armour. All of the 14 cm guns were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 58,
        "original": "Samuel Devenny suffered a heart attack four days after his beating. On 17 July he suffered a further heart attack and died. Thousands attended his funeral, and the mood was sufficiently angry that it was clear the annual Apprentice Boys'parade,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 46.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 59,
        "original": "\" The Snowmen \" was initially released as a standalone on DVD and Blu @-@ ray in the UK and North America. It was later included as part of the DVD / Blu @-@ ray box set Doctor Who : The Complete Seventh Series",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.42 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 60,
        "original": "Stevens'teams are built around solid basketball fundamentals and good team work, rather than individual basketball skill. His teams are known for their defense, forcing opponents into uncharacteristic mistakes. The secret to basketball \u2013 and life \u2013 is \" just to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 15.97 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 46.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 61,
        "original": "The battles of the American Civil War and at Lissa were very influential on the designs and tactics of the ironclad fleets that followed. In particular, it taught a generation of naval officers the misleading lesson that ramming was the best way to sink",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 62,
        "original": "The Hustler was a major critical and popular success, gaining a reputation as a modern classic. Its exploration of winning, losing, and character garnered a number of major awards ; it is also credited with helping to spark a resurgence in the popularity of pool",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 63,
        "original": "The losses were staggering : Gazan lost close to 40 percent of his division to death and wounds. Aside from losing five guns, 47 officers and 895 men under his command were captured, bringing the loss of effectives closer to 60",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 64,
        "original": "At 21 : 00 the first shells of what proved to be a two @-@ hour North Korean artillery and mortar preparation against the American river positions of 2nd Platoon. As the barrage rolled on, North Korean infantry crossed the river",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 65,
        "original": "Lester becomes infatuated with Jane's vain friend, Angela Hayes, after seeing her perform a half @-@ time dance routine at a high school basketball game. He starts having sexual fantasies about Angela, in which red rose petals are a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.30 GiB is allocated by PyTorch, and 57.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 66,
        "original": "On 30 December, violence escalated \" an order of magnitude \" as militants entered Mogadishu, which was quickly enveloped by a general state of lawlessness. On 30 \u2013 31 December, diplomats, including many stationed in offices elsewhere",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 67,
        "original": "Dodd was selected to represent Australia at the 2012 Summer Paralympics in London in equestrian events with her horse Waikiwi. These Games were her first, and she was the youngest Australian equestrian competitor. A fund",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 68,
        "original": "In 65, Gaius Calpurnius Piso, a Roman statesman, organized a conspiracy against Nero with the help of Subrius Flavus and Sulpicius Asper, a tribune and a centurion",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.96 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 51.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 69,
        "original": "The cost to rebuild Rome was immense, requiring funds the state treasury did not have. Nero devalued the Roman currency for the first time in the Empire's history. He reduced the weight of the denarius from 84 per Roman pound to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.02 GiB memory in use. Process 121765 has 15.92 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.36 GiB is allocated by PyTorch, and 61.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 70,
        "original": "After the armistice of Cassibile ( 8 September ), the German @-@ allied Italian Social Republic launched at least two raids on Gibraltar : one on the night of 4 \u2013 5 June 1944 with ten SM.79",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.06 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 52.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 71,
        "original": "The German Imperial Navy stipulated that the submarines must be transportable by rail, which imposed a maximum diameter of 3 @.@ 15 metres ( 10 ft 4 in ). The rushed planning effort \u2014 which had been assigned the name \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.06 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 52.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 72,
        "original": "Oxaziridines with unsubstituted or acylated nitrogens are capable of nitrogen atom transfer, although this reactivity has received considerably less attention.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.07 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.45 GiB is allocated by PyTorch, and 12.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 73,
        "original": "Maslin felt that Mendes directed with \" terrific visual flair \", saying his minimalist style balanced \" the mordant and bright \" and that he evoked the \" delicate, eroticized power @-@ playing vignettes \" of his theater work",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.07 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.41 GiB is allocated by PyTorch, and 56.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 74,
        "original": "Temnospondyli became a commonly used name at the turn of the century. Paleontologists included both embolomeres and rhachitomes in the group. Cope's Ganocephala and Labyrinthodonta fell out",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.06 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.41 GiB is allocated by PyTorch, and 52.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 75,
        "original": "A new government center was to be built on the hills northeast of Manila, or what is now Quezon City. Several government agencies have set up their headquarters in Quezon City but several key government offices still reside in Manila. However, many of the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.06 GiB memory in use. Process 121765 has 15.88 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 50.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 76,
        "original": "During the last week of August, US troops on these hills could see minor North Korean activity across the river, which they thought was North Koreans organizing the high ground on the west side of the Naktong against a possible American attack. There were occasional",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.08 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.41 GiB is allocated by PyTorch, and 60.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 77,
        "original": "The removal of the secondary armament, the rear turrets and their supporting structures was generally compensated by the addition of the flight deck, hangar, AA guns and more fuel, and the metacentric height increased.23 metres ( 9 @",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.06 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.44 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 50.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 78,
        "original": "Manila was occupied by British forces for twenty months, from 1762 to 1764, and used as a base for an unsuccessful attempt to conquer the Philippines during the Seven Years'War. Eventually, the British withdrew from Manila as per agreements",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.06 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.44 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.40 GiB is allocated by PyTorch, and 50.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 79,
        "original": "Following the departure of Ben Foster from Manchester United to Birmingham City, United manager Alex Ferguson declared that Amos would be Manchester United's third @-@ choice goalkeeper for the 2010 \u2013 11 season behind Edwin van der Sar and Tomasz",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.03 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.43 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 55.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 80,
        "original": "The current court complex is located at Pisang Emas Road. It comprises the High Court, the Sessions Court, and the Magistrate Court. Bintulu also has Syariah Subordinate Court, located at Tanjung Kidurong,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.02 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.44 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 53.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 81,
        "original": "Among the Beats, Gary Snyder and Allen Ginsberg in particular were influenced by the Imagist emphasis on Chinese and Japanese poetry. William Carlos Williams was another who had a strong effect on the Beat poets, encouraging poets like Lew Welch and writing an introduction for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 52.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 82,
        "original": "When word of the disaster that had overtaken 1st Battalion reached regimental headquarters, Freeman obtained the release of G and F Companies from 2nd Division reserve and sent the former to help 1st Battalion and the latter on the southern road",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.00 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.34 GiB is allocated by PyTorch, and 52.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 83,
        "original": "A project is underway to photograph the graves of and memorials to all service personnel from 1914 to the present day and make the images available to the public. The work is being carried out by The War Graves Photographic Project in conjunction with the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.46 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 51.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 84,
        "original": "The first Type UB I to enter service was UB @-@ 10, which formed the nucleus of the Flanders Flotilla, on 27 March 1915. By the end of April five more Type UB I boats had become operational",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.46 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 51.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 85,
        "original": "The band was formed by vocalist Jared Gomes, formerly of The Clue, also known as \" M.C.U.D. \" ( MC Underdog ), and guitarist Wes Geer, who became friends amidst the Orange County hardcore punk scene. G",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.48 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 56.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 86,
        "original": "The episode saw several major design changes for the series. \" The Snowmen \" is the debut of a redesigned TARDIS interior, as well as a new title sequence and variation of the theme tune. The new title sequence features a brief glimpse of",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.48 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 50.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 87,
        "original": "Modern scholarship generally holds that, while the Senate and more well @-@ off individuals welcomed Nero's death, the general populace was \" loyal to the end and beyond, for Otho and Vitellius both thought it worthwhile to appeal to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.46 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 56.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 88,
        "original": "An article in The Times on 17 February 1919 by Rudyard Kipling carried the Commission's proposal to a wider audience and described what the graves would look like. The article entitled War Graves : Work of Imperial Commission : Mr.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 16.46 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 56.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 89,
        "original": "The Battle of D\u00fcrenstein ( also known as the Battle of D\u00fcrrenstein, Battle of D\u00fcrnstein and Battle of Diernstein ; German : Gefecht bei D\u00fcrrenstein ), on 11 November 1805",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 56.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 90,
        "original": "Critics classify Little Gidding as a poem of fire with an emphasis on purgation and the Pentecostal fire. The beginning of the poem discusses time and winter, with attention paid to the arrival of summer. The images of snow,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 50.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 91,
        "original": "The few Austrian corps not trapped at Ulm withdrew toward Vienna, with the French in close pursuit. A Russian army under Gen. Mikhail Kutuzov also maneuvered away from the French, withdrawing to the east. At the Ill river on 22",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 50.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 92,
        "original": "In the late 1970s and early 1980s Franklin A. Davis synthesized the first N @-@ sulfonyloxaziridines, which act exclusively as oxygen transfer reagents, and are the most predominantly used class of ox",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 50.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 93,
        "original": "The ability of the tympanum and stapes to effectively transmit vibrations is called impedance matching. Early tetrapods like temnospondyls have thick stapes with poor impedance matching, so it is now thought that they were not used for hearing",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 50.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 94,
        "original": "Almost all of Manila sits on top of centuries of prehistoric alluvial deposits built by the waters of the Pasig and on some land reclaimed from Manila Bay. Manila's land has been altered substantially by human intervention, with considerable land reclamation",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 56.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 95,
        "original": "Bacon said that chance played a significant role in his work, and that he often approached a canvas without having a clear idea of what might emerge. This was especially the case in the mid to late 1940s, a period when he was",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 50.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 96,
        "original": "The 4th District ( 2015 population : 265 @,@ 046 ) covers Sampaloc.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 9.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 97,
        "original": "Manila is a major publishing center in the Philippines. Manila Bulletin, the Philippines'largest broadsheet newspaper by circulation, is headquartered inside Intramuros. Other major publishing companies in the country like The Manila Times, The Philippine Star and Manila Standard Today",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.98 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 44.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 98,
        "original": "Tacitus was the son of a procurator, who married into the elite family of Agricola. He entered his political life as a senator after Nero's death and, by Tacitus'own admission, owed much to Nero's rivals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 15.94 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 15.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 99,
        "original": "At 22 : 30 the fog lifted and Kouma saw that a North Korean pontoon bridge was being laid across the river directly in front of his position. Kouma's four vehicles attacked this structure, and after about a minute of heavy",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.95 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 63.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      }
    ],
    "statistics": {
      "total_samples": 100,
      "successful": 0,
      "success_rate": 0.0
    }
  },
  {
    "layer": 23,
    "samples": [
      {
        "sample_idx": 0,
        "original": "The history of Nero's reign is problematic in that no historical sources survived that were contemporary with Nero. These first histories at one time did exist and were described as biased and fantastical, either overly critical or praising of Nero. The original sources were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.95 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 63.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 1,
        "original": "Ironclads were designed for several roles, including as high seas battleships, coastal defense ships, and long @-@ range cruisers. The rapid evolution of warship design in the late 19th century transformed the ironclad from a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.95 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 65.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 2,
        "original": "The track became the group's sixth top @-@ ten hit in Ireland and the United Kingdom, while attaining top @-@ forty positions in both Belgian territories ( Flanders and Wallonia ), as well as in Australia, Canada,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.32 GiB is allocated by PyTorch, and 11.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 3,
        "original": "The band began touring in support of the album prior to its release, initiating touring with several free shows in the US. Followed by multiple appearances at festivals in Europe. They then joined Korn for their 2006 edition of Family Values Tour across",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 15.99 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 50.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 4,
        "original": "Imagism was a movement in early 20th @-@ century Anglo @-@ American poetry that favored precision of imagery and clear, sharp language.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.94 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.45 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 130.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 5,
        "original": "Kershaw finished 2012 with a 14 \u2013 9 record, a 2 @.@ 53 ERA ( leading the league ), 229 strikeouts, and 2272 \u2044 3 innings pitched, coming second in both categories",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 61.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 6,
        "original": "NY 31B began at an intersection with its parent route, NY 31, in the Cayuga County village of Weedsport. The highway went eastward, intersecting with NY 34 less than 0 @.@ 1 miles (",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 59.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 7,
        "original": "The unsuitability of unarmored iron for warship hulls meant that iron was only adopted as a building material for battleships when protected by armor. However, iron gave the naval architect many advantages. Iron allowed larger ships and more flexible design",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 59.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 8,
        "original": "Both the Provisional and Official IRA stepped up attacks after Bloody Sunday, with the tacit support of the residents. Local feelings changed, however, with the killing of Ranger William Best by the Official IRA. Best was a 19 @-@ year",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 59.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 9,
        "original": "On October 27, 2000, Gomes was arrested for possession of marijuana while the band was performing in Waterbury, Connecticut. He was released on a US $ 1 @,@ 500 bond. In 2001, Hed PE",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 59.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 10,
        "original": "The headquarters of the Philippine Coast Guard is located at the South Harbor in Port Area near Intramuros and Ermita. The Philippine Navy on the other hand has its headquarters in Naval Station Jose Andrada located along Roxas Boulevard in Malate.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 59.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 11,
        "original": "It was announced in March 2006 that Stone Sour's second album, which was tentatively titled \" Come What May, \" would be released on July 18, 2006. However, the release date for the album was pushed back",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.52 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 52.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 12,
        "original": "The Mediterranean U @-@ boat Campaign lasted approximately from 21 September 1941 to May 1944. The Kriegsmarine tried to isolate Gibraltar, Malta, and Suez and disrupt Britain's trade routes. More than sixty U",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.52 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 52.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 13,
        "original": "A neutron spectrometer on board the Lunar Prospector spacecraft detected enhanced concentrations of hydrogen close to the northern and southern lunar poles, including the crater Shackleton. At the end of this mission in July 1999, the spacecraft was crashed into the nearby",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.52 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 54.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 14,
        "original": "That same afternoon, the North Koreans sent an American prisoner up the hill to Schmitt with the message, \" You have one hour to surrender or be blown to pieces. \" Failing in frontal infantry attack to reduce the little defending force, the North",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 15,
        "original": "Although Gore was well received by the British establishment, the work suffered from what Gore called a \" tediousness of process \", and he considered requesting a transfer in 1798. In 1800 it ground to a halt because another board established by",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 16,
        "original": "On December 15, 2011, Lesnar was charged with hunting infractions on a trip to Alberta on November 19, 2010. Two charges were dropped, but Lesnar pleaded guilty to the charge of improper tagging of an animal",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 17,
        "original": "Carl Falk \u2014 writing, production, programming, instruments, guitar, background vocals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 5.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 18,
        "original": "Shot by November 2012, the music video was characterised, in several MTV News interviews, as \" bigger than anything we've done before \" by Zayn Malik, as \" a lot of hard work \" by Payne, as \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 19,
        "original": "A Company, 2nd Engineer Combat Battalion, moved to the south side of the Yongsan @-@ Naktong River road ; D Company of the 2nd Engineer Battalion was on the north side of the road. Approximately 2",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 20,
        "original": "Once a pattern is identified, the storm features ( such as length and curvature of banding features ) are further analyzed to arrive at a particular T @-@ number.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.91 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 138.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 21,
        "original": "On 1 July 2015, Amos returned to Bolton Wanderers following his release from Manchester United, signing a four @-@ year contract with the club.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.91 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.50 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 139.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 22,
        "original": "All of the 17 confirmed colossal heads remain in Mexico. Two heads from San Lorenzo are on permanent display at the Museo Nacional de Antropolog\u00eda in Mexico City. Seven of the San Lorenzo heads are on display in the Museo de Antrop",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.54 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 54.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 23,
        "original": "Nero's father was described by Suetonius as a murderer and a cheat who was charged by Emperor Tiberius with treason, adultery and incest. Tiberius died, allowing him to escape these charges. Nero's father died",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.54 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 18.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 24,
        "original": "\" Kiss You \" was written by Kristoffer Fogelmark, Kristian Lundin, Albin Nedler, Savan Kotecha, Shellback, and its producers, Carl Falk and Rami Yacoub. Falk, Kotecha",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.54 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 54.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 25,
        "original": "Jinks and Cohen involved Ball throughout the film's development, including casting and director selection. The producers met with about 20 interested directors, several of whom were considered \" A @-@ list \" at the time. Ball was not keen on",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 52.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 26,
        "original": "The most basal group of temnospondyls is the superfamily Edopoidea. Edopoids have several primitive or plesiomorphic features, including a single occipital condyle and a bone called the intertemporal that is absent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 54.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 27,
        "original": "The multi @-@ genus approach is based solely on the structure of the male flowers ; no other characters could be consistently associated with one genus or another. Four of the genera \u2014 Attalea ( in a narrow sense ), Orbignya,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 52.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 28,
        "original": "The Talmud adds that the sage Reb Meir Baal HaNess, Rabbi Meir or Rabbi Meir Baal HaNes ( Rabbi Meir the miracle maker ) was a Jewish sage who lived in the time of the Mishna",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.96 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.23 GiB is allocated by PyTorch, and 54.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 29,
        "original": "The 3rd District ( 2015 population : 197 @,@ 242 ) covers Binondo, Quiapo, San Nicolas and Santa Cruz.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.16 GiB is allocated by PyTorch, and 133.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 30,
        "original": "On July 15, Lesnar was notified of a potential anti @-@ doping policy violation by the United States Anti @-@ Doping Agency ( USADA ) stemming from an undisclosed banned substance in an out @-@ of @-@",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 31,
        "original": "Note that in this case the Dvorak T @-@ number ( in this case T2.5 ) was simply used as a guide but other factors determined how the NHC decided to set the system's intensity.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 14.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 32,
        "original": "A second prequel, titled \" Vastra Investigates \", was released online on 17 December 2012. At the end of a case, Vastra and Jenny converse with an officer from Scotland Yard and apologise for Strax's violent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 13.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 33,
        "original": "Gore served as district attorney until 1796. His principal matter of concern was the enforcement of U.S. neutrality with respect to the French Revolutionary Wars. He attempted several times to prosecute the French consul in Boston, Antoine Duplaine, for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 34,
        "original": "The origins of Imagism are to be found in two poems, Autumn and A City Sunset by T. E. Hulme. These were published in January 1909 by the Poets'Club in London in a booklet called For Christmas MD",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 35,
        "original": "The route turns south at Cedar Street, following the residential street into downtown Akron. Here, NY 93 intersects with CR 573 ( John Street ) at a junction that was once the western terminus of NY 267. At this intersection, NY",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 36,
        "original": "UB @-@ 1 and the still incomplete UB @-@ 15 were sold to the Austria @-@ Hungary in February 1915 ; both were dismantled and shipped to Pola in May. After one cruise under the German flag",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 37,
        "original": "His father died around 740. Du Fu would have been allowed to enter the civil service because of his father's rank, but he is thought to have given up the privilege in favour of one of his half brothers. He spent the next four",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.54 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 38,
        "original": "Chinese sawmill owners at Sibu and Bintulu were instructed by the Japanese to produce timber for repairs at oil fields and ship building. During the Japanese occupation, sawmills at Bintulu produced a total of 4 @,@ 000",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.54 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 39,
        "original": "After NY 18, NY 93 curves to the southeast, serving another residential stretch ahead of a junction with Youngstown \u2013 Wilson Road ( CR 36 ) on the eastern edge of Towers Corners. After this intersection, the homes give way to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.52 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 40,
        "original": "The new United States Navy Zumwalt @-@ class guided missile destroyer has been described as bearing resemblance to ironclads.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.90 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.16 GiB is allocated by PyTorch, and 140.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 41,
        "original": "The current Mayor of Manila is Joseph Estrada, who served as the President of the Philippines from 1998 @-@ 2001. He is also the head of the executive department of the city. The legislative arm which is composed of six",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 42,
        "original": "As of July 2016, Lesnar's eldest son, Brock Jr. is ranked # 1 in Saskatchewan and # 4 in all of Canada in amateur wrestling.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.53 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.16 GiB is allocated by PyTorch, and 137.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 43,
        "original": "Typhoon Maemi formed on September 4 from the monsoon trough in the western Pacific Ocean. It slowly intensified into a tropical storm while moving northwestward, and Maemi became a typhoon on September 8. That day, it quickly intensified",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 44,
        "original": "HMS Warrior is today a fully restored museum ship in Portsmouth, England",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 15.88 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 6.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 45,
        "original": "Several agencies issue Dvorak intensity numbers for tropical cyclones and their precursors, including the National Hurricane Center's Tropical Analysis and Forecast Branch ( TAFB ), the NOAA / NESDIS Satellite Analysis Branch ( SAB ), and the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 14.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 46,
        "original": "The growth of Bintulu's population is shown below :",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.90 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 5.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 47,
        "original": "While passing northeast of the Philippines, the typhoon caused light damage in the archipelago. The eye crossed over Okinawa, where Etau left 166 @,@ 800 people without power and caused 10 injuries. Near where Etau",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 48,
        "original": "On the morning of September 1 the 1st and 2nd Regiments of the NK 9th Division, in their first offensive of the war, stood only a few miles short of Yongsan after a successful river crossing and penetration",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 49,
        "original": "For the French, the survival of the Corps Mortier seemed nothing short of a miracle. The remainder of Gazan's division crossed the river the next morning and eventually recuperated in Vienna, which the French acquired by deception later in the month.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 50,
        "original": "This heavy night and day battle cost the NK 2nd Division most of its remaining offensive strength. The medical officer of the NK 17th Regiment, 2nd Division, captured a few days later, said that the division evacuated about 300",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 51,
        "original": "The selectivity of some hydroxylations may be drastically improved in some cases with the addition of coordinating groups alpha to the oxaziridine ring as oxaziridines 3b and 3c in the table above. In these",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 52,
        "original": "Due to local conditions it was sometimes necessary for the Commission to deviate from its standard design. In places prone to extreme weather or earthquakes, such as Thailand and Turkey, stone @-@ faced pedestal markers are used instead of the normal headstones.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 53,
        "original": "Increasing wind shear weakened the convection, and Parma deteriorated into a severe tropical storm on October 26. The next day, it began moving westward while passing about 345 km ( 215 mi ) north of Wake Island. A large",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 54,
        "original": "In 49 AD, Claudius married a fourth time, to Nero's mother Agrippina, despite her being his niece. To aid Claudius politically, young Nero was adopted in 50 and took the name Nero Claudius Caesar Drus",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.86 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 55,
        "original": "Head VI was the first of Bacon's paintings to reference Vel\u00e1zquez, whose portrait of Pope Innocent X haunted him throughout his career and inspired his series of \" screaming popes \", a loose series of which there are around 45 surviving",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 10.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 56,
        "original": "Outside of Warren Corners, the route heads across rural areas along the Cambria \u2013 Lockport town line. It soon enters the small hamlet of Hickory Corners, where the road passes under Lower Mountain Road ( CR 902 ). Access",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.59 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 57,
        "original": "The rear turrets, the barbettes and their supporting structures were removed beginning in early 1943 and the openings in the middle deck were covered by 152 mm plates salvaged from the turret armour. All of the 14 cm guns were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.88 GiB memory in use. Process 121890 has 16.59 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 58,
        "original": "Samuel Devenny suffered a heart attack four days after his beating. On 17 July he suffered a further heart attack and died. Thousands attended his funeral, and the mood was sufficiently angry that it was clear the annual Apprentice Boys'parade,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.88 GiB memory in use. Process 121890 has 16.59 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 43.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 59,
        "original": "\" The Snowmen \" was initially released as a standalone on DVD and Blu @-@ ray in the UK and North America. It was later included as part of the DVD / Blu @-@ ray box set Doctor Who : The Complete Seventh Series",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.59 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 60,
        "original": "Stevens'teams are built around solid basketball fundamentals and good team work, rather than individual basketball skill. His teams are known for their defense, forcing opponents into uncharacteristic mistakes. The secret to basketball \u2013 and life \u2013 is \" just to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.59 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 44.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 61,
        "original": "The battles of the American Civil War and at Lissa were very influential on the designs and tactics of the ironclad fleets that followed. In particular, it taught a generation of naval officers the misleading lesson that ramming was the best way to sink",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 62,
        "original": "The Hustler was a major critical and popular success, gaining a reputation as a modern classic. Its exploration of winning, losing, and character garnered a number of major awards ; it is also credited with helping to spark a resurgence in the popularity of pool",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 63,
        "original": "The losses were staggering : Gazan lost close to 40 percent of his division to death and wounds. Aside from losing five guns, 47 officers and 895 men under his command were captured, bringing the loss of effectives closer to 60",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.89 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.60 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 64,
        "original": "At 21 : 00 the first shells of what proved to be a two @-@ hour North Korean artillery and mortar preparation against the American river positions of 2nd Platoon. As the barrage rolled on, North Korean infantry crossed the river",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.58 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 61.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 65,
        "original": "Lester becomes infatuated with Jane's vain friend, Angela Hayes, after seeing her perform a half @-@ time dance routine at a high school basketball game. He starts having sexual fantasies about Angela, in which red rose petals are a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.58 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 61.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 66,
        "original": "On 30 December, violence escalated \" an order of magnitude \" as militants entered Mogadishu, which was quickly enveloped by a general state of lawlessness. On 30 \u2013 31 December, diplomats, including many stationed in offices elsewhere",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.58 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 61.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 67,
        "original": "Dodd was selected to represent Australia at the 2012 Summer Paralympics in London in equestrian events with her horse Waikiwi. These Games were her first, and she was the youngest Australian equestrian competitor. A fund",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.89 GiB memory in use. Process 121890 has 16.56 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 61.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 68,
        "original": "In 65, Gaius Calpurnius Piso, a Roman statesman, organized a conspiracy against Nero with the help of Subrius Flavus and Sulpicius Asper, a tribune and a centurion",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.89 GiB memory in use. Process 121890 has 16.56 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 57.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 69,
        "original": "The cost to rebuild Rome was immense, requiring funds the state treasury did not have. Nero devalued the Roman currency for the first time in the Empire's history. He reduced the weight of the denarius from 84 per Roman pound to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.57 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 55.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 70,
        "original": "After the armistice of Cassibile ( 8 September ), the German @-@ allied Italian Social Republic launched at least two raids on Gibraltar : one on the night of 4 \u2013 5 June 1944 with ten SM.79",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.57 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 55.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 71,
        "original": "The German Imperial Navy stipulated that the submarines must be transportable by rail, which imposed a maximum diameter of 3 @.@ 15 metres ( 10 ft 4 in ). The rushed planning effort \u2014 which had been assigned the name \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.92 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.57 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 55.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 72,
        "original": "Oxaziridines with unsubstituted or acylated nitrogens are capable of nitrogen atom transfer, although this reactivity has received considerably less attention.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 15.93 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.56 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 139.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 73,
        "original": "Maslin felt that Mendes directed with \" terrific visual flair \", saying his minimalist style balanced \" the mordant and bright \" and that he evoked the \" delicate, eroticized power @-@ playing vignettes \" of his theater work",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.02 GiB memory in use. Process 121765 has 15.99 GiB memory in use. Process 121890 has 16.35 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.36 GiB is allocated by PyTorch, and 62.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 74,
        "original": "Temnospondyli became a commonly used name at the turn of the century. Paleontologists included both embolomeres and rhachitomes in the group. Cope's Ganocephala and Labyrinthodonta fell out",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.03 GiB memory in use. Process 121765 has 15.98 GiB memory in use. Process 121890 has 16.35 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.36 GiB is allocated by PyTorch, and 72.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 75,
        "original": "A new government center was to be built on the hills northeast of Manila, or what is now Quezon City. Several government agencies have set up their headquarters in Quezon City but several key government offices still reside in Manila. However, many of the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.03 GiB memory in use. Process 121765 has 15.97 GiB memory in use. Process 121890 has 16.37 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 63.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 76,
        "original": "During the last week of August, US troops on these hills could see minor North Korean activity across the river, which they thought was North Koreans organizing the high ground on the west side of the Naktong against a possible American attack. There were occasional",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.08 GiB memory in use. Process 121765 has 15.92 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 63.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 77,
        "original": "The removal of the secondary armament, the rear turrets and their supporting structures was generally compensated by the addition of the flight deck, hangar, AA guns and more fuel, and the metacentric height increased.23 metres ( 9 @",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.09 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.43 GiB is allocated by PyTorch, and 60.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 78,
        "original": "Manila was occupied by British forces for twenty months, from 1762 to 1764, and used as a base for an unsuccessful attempt to conquer the Philippines during the Seven Years'War. Eventually, the British withdrew from Manila as per agreements",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 61.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 79,
        "original": "Following the departure of Ben Foster from Manchester United to Birmingham City, United manager Alex Ferguson declared that Amos would be Manchester United's third @-@ choice goalkeeper for the 2010 \u2013 11 season behind Edwin van der Sar and Tomasz",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 62.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 80,
        "original": "The current court complex is located at Pisang Emas Road. It comprises the High Court, the Sessions Court, and the Magistrate Court. Bintulu also has Syariah Subordinate Court, located at Tanjung Kidurong,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 61.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 81,
        "original": "Among the Beats, Gary Snyder and Allen Ginsberg in particular were influenced by the Imagist emphasis on Chinese and Japanese poetry. William Carlos Williams was another who had a strong effect on the Beat poets, encouraging poets like Lew Welch and writing an introduction for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 61.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 82,
        "original": "When word of the disaster that had overtaken 1st Battalion reached regimental headquarters, Freeman obtained the release of G and F Companies from 2nd Division reserve and sent the former to help 1st Battalion and the latter on the southern road",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 61.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 83,
        "original": "A project is underway to photograph the graves of and memorials to all service personnel from 1914 to the present day and make the images available to the public. The work is being carried out by The War Graves Photographic Project in conjunction with the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 61.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 84,
        "original": "The first Type UB I to enter service was UB @-@ 10, which formed the nucleus of the Flanders Flotilla, on 27 March 1915. By the end of April five more Type UB I boats had become operational",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 61.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 85,
        "original": "The band was formed by vocalist Jared Gomes, formerly of The Clue, also known as \" M.C.U.D. \" ( MC Underdog ), and guitarist Wes Geer, who became friends amidst the Orange County hardcore punk scene. G",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 62.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 86,
        "original": "The episode saw several major design changes for the series. \" The Snowmen \" is the debut of a redesigned TARDIS interior, as well as a new title sequence and variation of the theme tune. The new title sequence features a brief glimpse of",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.36 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 61.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 87,
        "original": "Modern scholarship generally holds that, while the Senate and more well @-@ off individuals welcomed Nero's death, the general populace was \" loyal to the end and beyond, for Otho and Vitellius both thought it worthwhile to appeal to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.35 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 62.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 88,
        "original": "An article in The Times on 17 February 1919 by Rudyard Kipling carried the Commission's proposal to a wider audience and described what the graves would look like. The article entitled War Graves : Work of Imperial Commission : Mr.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.85 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 62.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 89,
        "original": "The Battle of D\u00fcrenstein ( also known as the Battle of D\u00fcrrenstein, Battle of D\u00fcrnstein and Battle of Diernstein ; German : Gefecht bei D\u00fcrrenstein ), on 11 November 1805",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 62.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 90,
        "original": "Critics classify Little Gidding as a poem of fire with an emphasis on purgation and the Pentecostal fire. The beginning of the poem discusses time and winter, with attention paid to the arrival of summer. The images of snow,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 65.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 91,
        "original": "The few Austrian corps not trapped at Ulm withdrew toward Vienna, with the French in close pursuit. A Russian army under Gen. Mikhail Kutuzov also maneuvered away from the French, withdrawing to the east. At the Ill river on 22",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 65.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 92,
        "original": "In the late 1970s and early 1980s Franklin A. Davis synthesized the first N @-@ sulfonyloxaziridines, which act exclusively as oxygen transfer reagents, and are the most predominantly used class of ox",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 65.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 93,
        "original": "The ability of the tympanum and stapes to effectively transmit vibrations is called impedance matching. Early tetrapods like temnospondyls have thick stapes with poor impedance matching, so it is now thought that they were not used for hearing",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.17 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.50 GiB is allocated by PyTorch, and 65.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 94,
        "original": "Almost all of Manila sits on top of centuries of prehistoric alluvial deposits built by the waters of the Pasig and on some land reclaimed from Manila Bay. Manila's land has been altered substantially by human intervention, with considerable land reclamation",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 61.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 95,
        "original": "Bacon said that chance played a significant role in his work, and that he often approached a canvas without having a clear idea of what might emerge. This was especially the case in the mid to late 1940s, a period when he was",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 58.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 96,
        "original": "The 4th District ( 2015 population : 265 @,@ 046 ) covers Sampaloc.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.59 GiB is allocated by PyTorch, and 10.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 97,
        "original": "Manila is a major publishing center in the Philippines. Manila Bulletin, the Philippines'largest broadsheet newspaper by circulation, is headquartered inside Intramuros. Other major publishing companies in the country like The Manila Times, The Philippine Star and Manila Standard Today",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 52.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 98,
        "original": "Tacitus was the son of a procurator, who married into the elite family of Agricola. He entered his political life as a senator after Nero's death and, by Tacitus'own admission, owed much to Nero's rivals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 26.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 99,
        "original": "At 22 : 30 the fog lifted and Kouma saw that a North Korean pontoon bridge was being laid across the river directly in front of his position. Kouma's four vehicles attacked this structure, and after about a minute of heavy",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 61.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      }
    ],
    "statistics": {
      "total_samples": 100,
      "successful": 0,
      "success_rate": 0.0
    }
  },
  {
    "layer": 31,
    "samples": [
      {
        "sample_idx": 0,
        "original": "The history of Nero's reign is problematic in that no historical sources survived that were contemporary with Nero. These first histories at one time did exist and were described as biased and fantastical, either overly critical or praising of Nero. The original sources were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 68.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 1,
        "original": "Ironclads were designed for several roles, including as high seas battleships, coastal defense ships, and long @-@ range cruisers. The rapid evolution of warship design in the late 19th century transformed the ironclad from a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 2,
        "original": "The track became the group's sixth top @-@ ten hit in Ireland and the United Kingdom, while attaining top @-@ forty positions in both Belgian territories ( Flanders and Wallonia ), as well as in Australia, Canada,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.21 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 33.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 3,
        "original": "The band began touring in support of the album prior to its release, initiating touring with several free shows in the US. Followed by multiple appearances at festivals in Europe. They then joined Korn for their 2006 edition of Family Values Tour across",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.83 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 4,
        "original": "Imagism was a movement in early 20th @-@ century Anglo @-@ American poetry that favored precision of imagery and clear, sharp language.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 15.89 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 11.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 5,
        "original": "Kershaw finished 2012 with a 14 \u2013 9 record, a 2 @.@ 53 ERA ( leading the league ), 229 strikeouts, and 2272 \u2044 3 innings pitched, coming second in both categories",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 15.90 GiB memory in use. Process 121890 has 16.33 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 67.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 6,
        "original": "NY 31B began at an intersection with its parent route, NY 31, in the Cayuga County village of Weedsport. The highway went eastward, intersecting with NY 34 less than 0 @.@ 1 miles (",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.14 GiB memory in use. Process 121765 has 15.92 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.47 GiB is allocated by PyTorch, and 62.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 7,
        "original": "The unsuitability of unarmored iron for warship hulls meant that iron was only adopted as a building material for battleships when protected by armor. However, iron gave the naval architect many advantages. Iron allowed larger ships and more flexible design",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.14 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.47 GiB is allocated by PyTorch, and 62.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 8,
        "original": "Both the Provisional and Official IRA stepped up attacks after Bloody Sunday, with the tacit support of the residents. Local feelings changed, however, with the killing of Ranger William Best by the Official IRA. Best was a 19 @-@ year",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.14 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.47 GiB is allocated by PyTorch, and 62.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 9,
        "original": "On October 27, 2000, Gomes was arrested for possession of marijuana while the band was performing in Waterbury, Connecticut. He was released on a US $ 1 @,@ 500 bond. In 2001, Hed PE",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.14 GiB memory in use. Process 121765 has 15.93 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.47 GiB is allocated by PyTorch, and 62.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 10,
        "original": "The headquarters of the Philippine Coast Guard is located at the South Harbor in Port Area near Intramuros and Ermita. The Philippine Navy on the other hand has its headquarters in Naval Station Jose Andrada located along Roxas Boulevard in Malate.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.88 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 62.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 11,
        "original": "It was announced in March 2006 that Stone Sour's second album, which was tentatively titled \" Come What May, \" would be released on July 18, 2006. However, the release date for the album was pushed back",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 69.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 12,
        "original": "The Mediterranean U @-@ boat Campaign lasted approximately from 21 September 1941 to May 1944. The Kriegsmarine tried to isolate Gibraltar, Malta, and Suez and disrupt Britain's trade routes. More than sixty U",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 69.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 13,
        "original": "A neutron spectrometer on board the Lunar Prospector spacecraft detected enhanced concentrations of hydrogen close to the northern and southern lunar poles, including the crater Shackleton. At the end of this mission in July 1999, the spacecraft was crashed into the nearby",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 79.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 14,
        "original": "That same afternoon, the North Koreans sent an American prisoner up the hill to Schmitt with the message, \" You have one hour to surrender or be blown to pieces. \" Failing in frontal infantry attack to reduce the little defending force, the North",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 64.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 15,
        "original": "Although Gore was well received by the British establishment, the work suffered from what Gore called a \" tediousness of process \", and he considered requesting a transfer in 1798. In 1800 it ground to a halt because another board established by",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 69.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 16,
        "original": "On December 15, 2011, Lesnar was charged with hunting infractions on a trip to Alberta on November 19, 2010. Two charges were dropped, but Lesnar pleaded guilty to the charge of improper tagging of an animal",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 64.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 17,
        "original": "Carl Falk \u2014 writing, production, programming, instruments, guitar, background vocals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.21 GiB memory in use. Process 121765 has 15.86 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.58 GiB is allocated by PyTorch, and 24.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 18,
        "original": "Shot by November 2012, the music video was characterised, in several MTV News interviews, as \" bigger than anything we've done before \" by Zayn Malik, as \" a lot of hard work \" by Payne, as \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.86 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 69.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 19,
        "original": "A Company, 2nd Engineer Combat Battalion, moved to the south side of the Yongsan @-@ Naktong River road ; D Company of the 2nd Engineer Battalion was on the north side of the road. Approximately 2",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 79.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 20,
        "original": "Once a pattern is identified, the storm features ( such as length and curvature of banding features ) are further analyzed to arrive at a particular T @-@ number.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 22.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 21,
        "original": "On 1 July 2015, Amos returned to Bolton Wanderers following his release from Manchester United, signing a four @-@ year contract with the club.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 22.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 22,
        "original": "All of the 17 confirmed colossal heads remain in Mexico. Two heads from San Lorenzo are on permanent display at the Museo Nacional de Antropolog\u00eda in Mexico City. Seven of the San Lorenzo heads are on display in the Museo de Antrop",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 61.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 23,
        "original": "Nero's father was described by Suetonius as a murderer and a cheat who was charged by Emperor Tiberius with treason, adultery and incest. Tiberius died, allowing him to escape these charges. Nero's father died",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 21.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 24,
        "original": "\" Kiss You \" was written by Kristoffer Fogelmark, Kristian Lundin, Albin Nedler, Savan Kotecha, Shellback, and its producers, Carl Falk and Rami Yacoub. Falk, Kotecha",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 61.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 25,
        "original": "Jinks and Cohen involved Ball throughout the film's development, including casting and director selection. The producers met with about 20 interested directors, several of whom were considered \" A @-@ list \" at the time. Ball was not keen on",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 67.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 26,
        "original": "The most basal group of temnospondyls is the superfamily Edopoidea. Edopoids have several primitive or plesiomorphic features, including a single occipital condyle and a bone called the intertemporal that is absent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 61.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 27,
        "original": "The multi @-@ genus approach is based solely on the structure of the male flowers ; no other characters could be consistently associated with one genus or another. Four of the genera \u2014 Attalea ( in a narrow sense ), Orbignya,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 67.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 28,
        "original": "The Talmud adds that the sage Reb Meir Baal HaNess, Rabbi Meir or Rabbi Meir Baal HaNes ( Rabbi Meir the miracle maker ) was a Jewish sage who lived in the time of the Mishna",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 61.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 29,
        "original": "The 3rd District ( 2015 population : 197 @,@ 242 ) covers Binondo, Quiapo, San Nicolas and Santa Cruz.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 15.87 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 15.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 30,
        "original": "On July 15, Lesnar was notified of a potential anti @-@ doping policy violation by the United States Anti @-@ Doping Agency ( USADA ) stemming from an undisclosed banned substance in an out @-@ of @-@",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 15.89 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 66.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 31,
        "original": "Note that in this case the Dvorak T @-@ number ( in this case T2.5 ) was simply used as a guide but other factors determined how the NHC decided to set the system's intensity.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.16 GiB memory in use. Process 121765 has 15.89 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 30.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 32,
        "original": "A second prequel, titled \" Vastra Investigates \", was released online on 17 December 2012. At the end of a case, Vastra and Jenny converse with an officer from Scotland Yard and apologise for Strax's violent",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.16 GiB memory in use. Process 121765 has 15.90 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 35.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 33,
        "original": "Gore served as district attorney until 1796. His principal matter of concern was the enforcement of U.S. neutrality with respect to the French Revolutionary Wars. He attempted several times to prosecute the French consul in Boston, Antoine Duplaine, for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.15 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.30 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.49 GiB is allocated by PyTorch, and 64.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 34,
        "original": "The origins of Imagism are to be found in two poems, Autumn and A City Sunset by T. E. Hulme. These were published in January 1909 by the Poets'Club in London in a booklet called For Christmas MD",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.15 GiB memory in use. Process 121765 has 15.91 GiB memory in use. Process 121890 has 16.29 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.49 GiB is allocated by PyTorch, and 64.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 35,
        "original": "The route turns south at Cedar Street, following the residential street into downtown Akron. Here, NY 93 intersects with CR 573 ( John Street ) at a junction that was once the western terminus of NY 267. At this intersection, NY",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.15 GiB memory in use. Process 121765 has 15.92 GiB memory in use. Process 121890 has 16.29 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.49 GiB is allocated by PyTorch, and 64.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 36,
        "original": "UB @-@ 1 and the still incomplete UB @-@ 15 were sold to the Austria @-@ Hungary in February 1915 ; both were dismantled and shipped to Pola in May. After one cruise under the German flag",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.15 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.27 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.49 GiB is allocated by PyTorch, and 64.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 37,
        "original": "His father died around 740. Du Fu would have been allowed to enter the civil service because of his father's rank, but he is thought to have given up the privilege in favour of one of his half brothers. He spent the next four",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 16.15 GiB memory in use. Process 121765 has 15.94 GiB memory in use. Process 121890 has 16.26 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 70.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 38,
        "original": "Chinese sawmill owners at Sibu and Bintulu were instructed by the Japanese to produce timber for repairs at oil fields and ship building. During the Japanese occupation, sawmills at Bintulu produced a total of 4 @,@ 000",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.15 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.27 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 64.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 39,
        "original": "After NY 18, NY 93 curves to the southeast, serving another residential stretch ahead of a junction with Youngstown \u2013 Wilson Road ( CR 36 ) on the eastern edge of Towers Corners. After this intersection, the homes give way to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.15 GiB memory in use. Process 121765 has 15.95 GiB memory in use. Process 121890 has 16.27 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 64.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 40,
        "original": "The new United States Navy Zumwalt @-@ class guided missile destroyer has been described as bearing resemblance to ironclads.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.13 GiB memory in use. Process 121765 has 15.99 GiB memory in use. Process 121890 has 16.25 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.49 GiB is allocated by PyTorch, and 35.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 41,
        "original": "The current Mayor of Manila is Joseph Estrada, who served as the President of the Philippines from 1998 @-@ 2001. He is also the head of the executive department of the city. The legislative arm which is composed of six",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.10 GiB memory in use. Process 121765 has 16.00 GiB memory in use. Process 121890 has 16.26 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.43 GiB is allocated by PyTorch, and 62.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 42,
        "original": "As of July 2016, Lesnar's eldest son, Brock Jr. is ranked # 1 in Saskatchewan and # 4 in all of Canada in amateur wrestling.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.08 GiB memory in use. Process 121765 has 16.11 GiB memory in use. Process 121890 has 16.16 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 22.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 43,
        "original": "Typhoon Maemi formed on September 4 from the monsoon trough in the western Pacific Ocean. It slowly intensified into a tropical storm while moving northwestward, and Maemi became a typhoon on September 8. That day, it quickly intensified",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.08 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.06 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 63.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 44,
        "original": "HMS Warrior is today a fully restored museum ship in Portsmouth, England",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.07 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.06 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.45 GiB is allocated by PyTorch, and 9.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 45,
        "original": "Several agencies issue Dvorak intensity numbers for tropical cyclones and their precursors, including the National Hurricane Center's Tropical Analysis and Forecast Branch ( TAFB ), the NOAA / NESDIS Satellite Analysis Branch ( SAB ), and the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.07 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.06 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.44 GiB is allocated by PyTorch, and 30.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 46,
        "original": "The growth of Bintulu's population is shown below :",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.07 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.06 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.45 GiB is allocated by PyTorch, and 21.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 47,
        "original": "While passing northeast of the Philippines, the typhoon caused light damage in the archipelago. The eye crossed over Okinawa, where Etau left 166 @,@ 800 people without power and caused 10 injuries. Near where Etau",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.06 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 64.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 48,
        "original": "On the morning of September 1 the 1st and 2nd Regiments of the NK 9th Division, in their first offensive of the war, stood only a few miles short of Yongsan after a successful river crossing and penetration",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 64.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 49,
        "original": "For the French, the survival of the Corps Mortier seemed nothing short of a miracle. The remainder of Gazan's division crossed the river the next morning and eventually recuperated in Vienna, which the French acquired by deception later in the month.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 69.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 50,
        "original": "This heavy night and day battle cost the NK 2nd Division most of its remaining offensive strength. The medical officer of the NK 17th Regiment, 2nd Division, captured a few days later, said that the division evacuated about 300",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.24 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 72.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 51,
        "original": "The selectivity of some hydroxylations may be drastically improved in some cases with the addition of coordinating groups alpha to the oxaziridine ring as oxaziridines 3b and 3c in the table above. In these",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 64.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 52,
        "original": "Due to local conditions it was sometimes necessary for the Commission to deviate from its standard design. In places prone to extreme weather or earthquakes, such as Thailand and Turkey, stone @-@ faced pedestal markers are used instead of the normal headstones.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 64.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 53,
        "original": "Increasing wind shear weakened the convection, and Parma deteriorated into a severe tropical storm on October 26. The next day, it began moving westward while passing about 345 km ( 215 mi ) north of Wake Island. A large",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 64.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 54,
        "original": "In 49 AD, Claudius married a fourth time, to Nero's mother Agrippina, despite her being his niece. To aid Claudius politically, young Nero was adopted in 50 and took the name Nero Claudius Caesar Drus",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 69.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 55,
        "original": "Head VI was the first of Bacon's paintings to reference Vel\u00e1zquez, whose portrait of Pope Innocent X haunted him throughout his career and inspired his series of \" screaming popes \", a loose series of which there are around 45 surviving",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.04 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.41 GiB is allocated by PyTorch, and 25.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 56,
        "original": "Outside of Warren Corners, the route heads across rural areas along the Cambria \u2013 Lockport town line. It soon enters the small hamlet of Hickory Corners, where the road passes under Lower Mountain Road ( CR 902 ). Access",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.09 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 77.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 57,
        "original": "The rear turrets, the barbettes and their supporting structures were removed beginning in early 1943 and the openings in the middle deck were covered by 152 mm plates salvaged from the turret armour. All of the 14 cm guns were",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 64.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 58,
        "original": "Samuel Devenny suffered a heart attack four days after his beating. On 17 July he suffered a further heart attack and died. Thousands attended his funeral, and the mood was sufficiently angry that it was clear the annual Apprentice Boys'parade,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.05 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 16.08 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 58.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 59,
        "original": "\" The Snowmen \" was initially released as a standalone on DVD and Blu @-@ ray in the UK and North America. It was later included as part of the DVD / Blu @-@ ray box set Doctor Who : The Complete Seventh Series",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 16.23 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 80.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 60,
        "original": "Stevens'teams are built around solid basketball fundamentals and good team work, rather than individual basketball skill. His teams are known for their defense, forcing opponents into uncharacteristic mistakes. The secret to basketball \u2013 and life \u2013 is \" just to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.96 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 75.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 61,
        "original": "The battles of the American Civil War and at Lissa were very influential on the designs and tactics of the ironclad fleets that followed. In particular, it taught a generation of naval officers the misleading lesson that ramming was the best way to sink",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 62,
        "original": "The Hustler was a major critical and popular success, gaining a reputation as a modern classic. Its exploration of winning, losing, and character garnered a number of major awards ; it is also credited with helping to spark a resurgence in the popularity of pool",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 63,
        "original": "The losses were staggering : Gazan lost close to 40 percent of his division to death and wounds. Aside from losing five guns, 47 officers and 895 men under his command were captured, bringing the loss of effectives closer to 60",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 64,
        "original": "At 21 : 00 the first shells of what proved to be a two @-@ hour North Korean artillery and mortar preparation against the American river positions of 2nd Platoon. As the barrage rolled on, North Korean infantry crossed the river",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 65,
        "original": "Lester becomes infatuated with Jane's vain friend, Angela Hayes, after seeing her perform a half @-@ time dance routine at a high school basketball game. He starts having sexual fantasies about Angela, in which red rose petals are a",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.22 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.93 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 84.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 66,
        "original": "On 30 December, violence escalated \" an order of magnitude \" as militants entered Mogadishu, which was quickly enveloped by a general state of lawlessness. On 30 \u2013 31 December, diplomats, including many stationed in offices elsewhere",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 63.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 67,
        "original": "Dodd was selected to represent Australia at the 2012 Summer Paralympics in London in equestrian events with her horse Waikiwi. These Games were her first, and she was the youngest Australian equestrian competitor. A fund",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 19.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 68,
        "original": "In 65, Gaius Calpurnius Piso, a Roman statesman, organized a conspiracy against Nero with the help of Subrius Flavus and Sulpicius Asper, a tribune and a centurion",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 13.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 65.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 69,
        "original": "The cost to rebuild Rome was immense, requiring funds the state treasury did not have. Nero devalued the Roman currency for the first time in the Empire's history. He reduced the weight of the denarius from 84 per Roman pound to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 70.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 70,
        "original": "After the armistice of Cassibile ( 8 September ), the German @-@ allied Italian Social Republic launched at least two raids on Gibraltar : one on the night of 4 \u2013 5 June 1944 with ten SM.79",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 70.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 71,
        "original": "The German Imperial Navy stipulated that the submarines must be transportable by rail, which imposed a maximum diameter of 3 @.@ 15 metres ( 10 ft 4 in ). The rushed planning effort \u2014 which had been assigned the name \"",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.52 GiB is allocated by PyTorch, and 70.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 72,
        "original": "Oxaziridines with unsubstituted or acylated nitrogens are capable of nitrogen atom transfer, although this reactivity has received considerably less attention.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.19 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 22.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 73,
        "original": "Maslin felt that Mendes directed with \" terrific visual flair \", saying his minimalist style balanced \" the mordant and bright \" and that he evoked the \" delicate, eroticized power @-@ playing vignettes \" of his theater work",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.18 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.98 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 67.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 74,
        "original": "Temnospondyli became a commonly used name at the turn of the century. Paleontologists included both embolomeres and rhachitomes in the group. Cope's Ganocephala and Labyrinthodonta fell out",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.21 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 70.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 75,
        "original": "A new government center was to be built on the hills northeast of Manila, or what is now Quezon City. Several government agencies have set up their headquarters in Quezon City but several key government offices still reside in Manila. However, many of the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.21 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 64.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 76,
        "original": "During the last week of August, US troops on these hills could see minor North Korean activity across the river, which they thought was North Koreans organizing the high ground on the west side of the Naktong against a possible American attack. There were occasional",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.21 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 64.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 77,
        "original": "The removal of the secondary armament, the rear turrets and their supporting structures was generally compensated by the addition of the flight deck, hangar, AA guns and more fuel, and the metacentric height increased.23 metres ( 9 @",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.21 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 64.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 78,
        "original": "Manila was occupied by British forces for twenty months, from 1762 to 1764, and used as a base for an unsuccessful attempt to conquer the Philippines during the Seven Years'War. Eventually, the British withdrew from Manila as per agreements",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.21 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.94 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 64.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 79,
        "original": "Following the departure of Ben Foster from Manchester United to Birmingham City, United manager Alex Ferguson declared that Amos would be Manchester United's third @-@ choice goalkeeper for the 2010 \u2013 11 season behind Edwin van der Sar and Tomasz",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.92 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 76.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 80,
        "original": "The current court complex is located at Pisang Emas Road. It comprises the High Court, the Sessions Court, and the Magistrate Court. Bintulu also has Syariah Subordinate Court, located at Tanjung Kidurong,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 61.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 81,
        "original": "Among the Beats, Gary Snyder and Allen Ginsberg in particular were influenced by the Imagist emphasis on Chinese and Japanese poetry. William Carlos Williams was another who had a strong effect on the Beat poets, encouraging poets like Lew Welch and writing an introduction for",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 15.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.21 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 61.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 82,
        "original": "When word of the disaster that had overtaken 1st Battalion reached regimental headquarters, Freeman obtained the release of G and F Companies from 2nd Division reserve and sent the former to help 1st Battalion and the latter on the southern road",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 61.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 83,
        "original": "A project is underway to photograph the graves of and memorials to all service personnel from 1914 to the present day and make the images available to the public. The work is being carried out by The War Graves Photographic Project in conjunction with the",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.22 GiB memory in use. Process 121890 has 15.91 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 61.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 84,
        "original": "The first Type UB I to enter service was UB @-@ 10, which formed the nucleus of the Flanders Flotilla, on 27 March 1915. By the end of April five more Type UB I boats had become operational",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.20 GiB memory in use. Process 121890 has 15.93 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.57 GiB is allocated by PyTorch, and 61.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 85,
        "original": "The band was formed by vocalist Jared Gomes, formerly of The Clue, also known as \" M.C.U.D. \" ( MC Underdog ), and guitarist Wes Geer, who became friends amidst the Orange County hardcore punk scene. G",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 67.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 86,
        "original": "The episode saw several major design changes for the series. \" The Snowmen \" is the debut of a redesigned TARDIS interior, as well as a new title sequence and variation of the theme tune. The new title sequence features a brief glimpse of",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 70.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 87,
        "original": "Modern scholarship generally holds that, while the Senate and more well @-@ off individuals welcomed Nero's death, the general populace was \" loyal to the end and beyond, for Otho and Vitellius both thought it worthwhile to appeal to",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 67.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 88,
        "original": "An article in The Times on 17 February 1919 by Rudyard Kipling carried the Commission's proposal to a wider audience and described what the graves would look like. The article entitled War Graves : Work of Imperial Commission : Mr.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 67.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 89,
        "original": "The Battle of D\u00fcrenstein ( also known as the Battle of D\u00fcrrenstein, Battle of D\u00fcrnstein and Battle of Diernstein ; German : Gefecht bei D\u00fcrrenstein ), on 11 November 1805",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 67.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 90,
        "original": "Critics classify Little Gidding as a poem of fire with an emphasis on purgation and the Pentecostal fire. The beginning of the poem discusses time and winter, with attention paid to the arrival of summer. The images of snow,",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 70.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 91,
        "original": "The few Austrian corps not trapped at Ulm withdrew toward Vienna, with the French in close pursuit. A Russian army under Gen. Mikhail Kutuzov also maneuvered away from the French, withdrawing to the east. At the Ill river on 22",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 70.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 92,
        "original": "In the late 1970s and early 1980s Franklin A. Davis synthesized the first N @-@ sulfonyloxaziridines, which act exclusively as oxygen transfer reagents, and are the most predominantly used class of ox",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 70.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 93,
        "original": "The ability of the tympanum and stapes to effectively transmit vibrations is called impedance matching. Early tetrapods like temnospondyls have thick stapes with poor impedance matching, so it is now thought that they were not used for hearing",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 70.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 94,
        "original": "Almost all of Manila sits on top of centuries of prehistoric alluvial deposits built by the waters of the Pasig and on some land reclaimed from Manila Bay. Manila's land has been altered substantially by human intervention, with considerable land reclamation",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 5.88 MiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 67.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 95,
        "original": "Bacon said that chance played a significant role in his work, and that he often approached a canvas without having a clear idea of what might emerge. This was especially the case in the mid to late 1940s, a period when he was",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.24 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.95 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 70.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 96,
        "original": "The 4th District ( 2015 population : 265 @,@ 046 ) covers Sampaloc.",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 21.88 MiB is free. Including non-PyTorch memory, this process has 16.20 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.97 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.58 GiB is allocated by PyTorch, and 11.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 97,
        "original": "Manila is a major publishing center in the Philippines. Manila Bulletin, the Philippines'largest broadsheet newspaper by circulation, is headquartered inside Intramuros. Other major publishing companies in the country like The Manila Times, The Philippine Star and Manila Standard Today",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 9.88 MiB is free. Including non-PyTorch memory, this process has 16.32 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.85 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.66 GiB is allocated by PyTorch, and 58.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 98,
        "original": "Tacitus was the son of a procurator, who married into the elite family of Agricola. He entered his political life as a senator after Nero's death and, by Tacitus'own admission, owed much to Nero's rivals",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 16.32 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.86 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 22.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      },
      {
        "sample_idx": 99,
        "original": "At 22 : 30 the fog lifted and Kouma saw that a North Korean pontoon bridge was being laid across the river directly in front of his position. Kouma's four vehicles attacked this structure, and after about a minute of heavy",
        "predicted": null,
        "success": false,
        "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 16.32 GiB memory in use. Process 121765 has 16.19 GiB memory in use. Process 121890 has 15.87 GiB memory in use. Process 122917 has 15.52 GiB memory in use. Process 123330 has 15.52 GiB memory in use. Of the allocated memory 15.63 GiB is allocated by PyTorch, and 81.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
      }
    ],
    "statistics": {
      "total_samples": 100,
      "successful": 0,
      "success_rate": 0.0
    }
  }
]